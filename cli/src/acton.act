import argparse
import file
import json
import process
import term
import testing

from buildy import *
from testing import TestInfo

def get_zig_local_cache_dir(file_cap: file.FileCap):
    fs = file.FS(file_cap)
    return file.join_path([fs.homedir(), ".cache", "acton", "zig-local-cache"])

def get_zig_global_cache_dir(file_cap: file.FileCap):
    fs = file.FS(file_cap)
    return file.join_path([fs.homedir(), ".cache", "acton", "zig-global-cache"])

def base_path(file_cap: file.FileCap):
    fs = file.FS(file_cap)
    return fs.exepath()[0:-len("/bin/acton")]

def warn_on_large_zig_global_cache(cap: file.FileCap):
    fs = file.FS(cap)
    last_warn_file = file.join_path([get_zig_global_cache_dir(cap), "last_warn"])
    warn_level: int = 10 # start to warn at 10GB
    try:
        last_warn = int(file.ReadFile(file.ReadFileCap(cap), last_warn_file).read().decode())
        warn_level = last_warn + 1 # warn in 1GB increments
    except:
        try:
            f = file.WriteFile(file.WriteFileCap(cap), last_warn_file)
            f.write(str(warn_level).encode())
            f.close()
        except:
            # The cache dir probably doesn't exist, just ignore
            pass

    cache_dir = get_zig_global_cache_dir(cap)
    total_size: int = 0
    for f in fs.walk(cache_dir):
        total_size += int(f.size)
    gb = 1024 * 1024 * 1024
    if total_size > warn_level * gb:
        print("WARN: The global cache has grown to %dMB" % (total_size // (1024*1024)))
        print("HINT: You can clear the cache with with: rm -rf %s" % cache_dir)
        print("INFO: Do NOT clear the cache if you are offline or have a slow connection.")
        print("INFO: The global cache stores downloaded package dependencies as well as")
        print("INFO: compiled artifacts for common libraries, like libc.")
        print("INFO: Another warning will be issued when the cache grows by another 1GB.")
        print("")
        # write new warn level
        try:
            f = file.WriteFile(file.WriteFileCap(cap), last_warn_file)
            f.write(str(total_size // gb).encode())
            f.close()
        except Exception as e:
            print("WARN: Could not write new warn level to", last_warn_file)
            print(e)
    if total_size == 0:
        print("INFO: Acton global cache is empty: rebuilding common libraries (e.g. libc) which will take some time...")

def clean_zig_local_cache(cap: file.FileCap):
    fs = file.FS(cap)
    cache_dir = get_zig_local_cache_dir(cap)
    total_size = 0
    for f in fs.walk(cache_dir):
        total_size += f.size
    gb = 1024 * 1024 * 1024
    limit = 5 * gb
    if total_size > limit:
        print("Build cache (", total_size // (1024*1024), "MB) over %dGB, cleaning it up." % (int(limit // gb)))
        fs.rmtree(cache_dir)
        total_size = 0
    if total_size == 0:
        print("INFO: Acton local cache is empty: rebuilding Acton base which will take some time...")

def write_buildzig(file_cap, build_config: BuildConfig):
    fs = file.FS(file_cap)

    def get_build_zig_templates():
        # Read the build.zig template
        build_zig_template = file.ReadFile(
            file.ReadFileCap(file_cap),
            file.join_path([base_path(file_cap), "builder", "build.zig"])).read().decode()
        build_zig_zon_template = file.ReadFile(
            file.ReadFileCap(file_cap),
            file.join_path([base_path(file_cap), "builder", "build.zig.zon"])).read().decode()
        return build_zig_template, build_zig_zon_template

    build_zig_tpl, build_zig_zon_tpl = get_build_zig_templates()
    # Write build.zig
    b_file = file.WriteFile(file.WriteFileCap(file_cap), "build.zig")
    await async b_file.write(gen_buildzig(build_zig_tpl, build_config).encode())
    await async b_file.close()
    # Write build.zig.zon
    bzz_file = file.WriteFile(file.WriteFileCap(file_cap), "build.zig.zon")
    await async bzz_file.write(gen_buildzigzon(build_zig_zon_tpl, build_config).encode())
    await async bzz_file.close()


actor CompilerRunner(process_cap, env, args, wdir=None, on_exit: ?action(int, int, bytes, bytes) -> None=None, on_error: ?action(str) -> None=None, print_output: bool=True, exe="actonc"):
    """Run the actonc compiler

    Will run actonc with the provided command and arguments. It is possible to
    inject callbacks when actonc exits or encounters an error. If no callbacks
    are provided, the default behavior is to exit when actonc does, possibly
    with an error message. Similarly, if actonc encounters an error, it will
    print the error message and exit.
    """
    var stdout_buf = b""
    var stderr_buf = b""

    def on_actonc_stderr(p, data):
        stderr_buf += data
        if print_output:
            print(data.decode(), end="")

    def on_actonc_stdout(p, data):
        stdout_buf += data
        if print_output:
            print(data.decode(), end="")

    def on_actonc_exit(p, exit_code, term_signal):
        if on_exit is not None:
            on_exit(exit_code, term_signal, stdout_buf, stderr_buf)
        else:
            if exit_code != 0:
                print("actonc exited with code: ", exit_code, " terminated with signal:", term_signal)
            env.exit(exit_code)

    def on_actonc_error(p, error: str):
        if on_error is not None:
            on_error(error)
        else:
            print("Error from process:", error)
            env.exit(1)

    fs = file.FS(file.FileCap(env.cap))
    # We find the path to actonc by looking at the executable path of the
    # current process. Since we are called 'acton', we just add a 'c'.
    cmd = [fs.exepath() + ("c" if exe == "actonc" else "")] + args
    p = process.Process(process_cap, cmd, on_actonc_stdout, on_actonc_stderr, on_actonc_exit, on_actonc_error, wdir)


actor BuildProject(process_cap, env, args, on_build_success: action(str) -> None, on_build_failure: action(int, int, str) -> None, build_tests: bool=False, files: list[str]=[]):
    """Build the project including dependencies

    - check for dependencies.json, if found, download dependencies
    - build dependencies
    - build
    """
    fcap = file.FileCap(env.cap)
    rfcap = file.ReadFileCap(fcap)
    fs = file.FS(fcap)
    lock_file = None
    remaining_deps = {}
    zig_global_cache_dir = get_zig_global_cache_dir(file.FileCap(env.cap))
    if len(files) > 1:
        raise NotImplementedError("Multiple files not supported yet")

    dep_path_overrides = {}
    for dep_arg in args.get_strlist("dep"):
        parts = dep_arg.split("=", 1)
        dep_name, dep_path = parts[0], parts[1]
        # Ensure we have absolute paths
        abs_path = file.resolve_relative_path(fs.cwd(), dep_path)
        dep_path_overrides[dep_name] = abs_path

    var build_config = BuildConfig()

    def _on_actonc_exit(exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            on_build_success(stdout_buf.decode())
        else:
            on_build_failure(exit_code, term_signal, stdout_buf.decode() + stderr_buf.decode())

    def _on_actonc_failure(error: str):
        on_build_failure(-999, -999, error)

    def build_project():
        search_paths = []
        for dep_name, dep in build_config.dependencies.items():
            dep_hash = dep.hash
            dep_path = dep.path
            if dep_path is not None:
                # TODO: deconstruct and put together to get OS independent path? i.e. flip / to \ on windows
                if len(dep_path) == 0:
                    pass
                elif dep_path[0] == "/":
                    search_paths.append(file.join_path([dep_path, "out", "types"]))
                else:
                    search_paths.append(file.join_path([fs.cwd(), dep_path, "out", "types"]))
            elif dep_hash is not None:
                # For dependencies with hashes, we have previously copied them
                # from the Zig global cache to .build/deps/
                dep_dirname = dep_name + "-" + dep_hash
                search_paths.append(file.join_path([fs.cwd(), ".build", "deps", dep_dirname, "out", "types"]))
            else:
                raise ValueError("Dependency %s has no path or hash" % dep_name)
        search_path_arg = []
        for sp in search_paths:
            search_path_arg.extend(["--searchpath", sp])
        cmdargs = []
        if files == []:
            cmdargs.extend(["build"])
        else:
            cmdargs.extend([files[0]])
        cmdargs.extend(build_cmd_args(args))
        if build_tests:
            cmdargs.append("--dev")
            cmdargs.append("--test")
        cmd = cmdargs + search_path_arg
        cr = CompilerRunner(
            process_cap,
            env,
            cmd,
            None,
            _on_actonc_exit,
            _on_actonc_failure,
            print_output=not build_tests
        )

    def _on_dep_actonc_exit(dep_name, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            print("Dependency", dep_name, "built successfully")
            try:
                del remaining_deps[dep_name]
            except KeyError:
                pass

            if len(remaining_deps) == 0:
                print("All dependencies built, building main project")
                build_project()
        else:
            # TODO: do better
            raise ValueError("Error building dependency")


    def on_dep_build_error(name, error):
        print("Error building dependency", name, error)
        env.exit(1)

    def build_deps():
        # Find dependencies and compile them first
        if len(build_config.dependencies) == 0:
            build_project()
        else:
            print("Building dependencies:")
            for dep_name, dep in build_config.dependencies.items():
                dep_hash = dep.hash
                dep_path = dep.path
                path = ""
                if dep_path is not None:
                    path = dep_path
                elif dep_hash is not None:
                    path = file.join_path([".build", "deps", dep_name + "-" + dep_hash])
                else:
                    raise ValueError("Dependency %s has no path or hash" % dep_name)
                print(" -", dep_name)
                remaining_deps[dep_name] = True
                dep_args = []
                for dep_arg in args.get_strlist("dep"):
                    dep_args.extend(["--dep", dep_arg])
                cmd = ["build"] + build_cmd_args(args) + ["--keepbuild"] + dep_args
                cr = CompilerRunner(
                    process_cap,
                    env,
                    cmd,
                    path,
                    lambda exit_code, term_signal, stdout_buf, stderr_buf: _on_dep_actonc_exit(dep_name, exit_code, term_signal, stdout_buf, stderr_buf),
                    lambda error_msg: on_dep_build_error(dep_name, error_msg),
                    exe="acton"
                )

    def check_deps():
        # 1. fetch dependencies (into zig global cache)
        # 2. copy dependencies from zig global cache to deps/
        # 3. build dependencies
        # 4. build project
        deps_dir = set()
        try:
            await async fs.mkdir(".build")
        except:
            pass

        try:
            await async fs.mkdir(file.join_path([".build", "deps"]))
        except:
            pass

        try:
            deps_dir = set(fs.listdir(file.join_path([".build", "deps"])))
        except OSError:
            pass

        for dep_name, dep in build_config.dependencies.items():
            # Does deps/X exist?
            dep_hash = dep.hash
            dep_path = dep.path
            if dep_path is not None:
                pass
            elif dep_hash is not None:
                dep_dirname = dep_name + "-" + dep_hash
                if dep_dirname not in deps_dir:
                    src = file.join_path([zig_global_cache_dir, "p", dep_hash])
                    dst = file.join_path([fs.cwd(), ".build", "deps", dep_dirname])
                    try:
                        await async fs.mkdir(dst)
                    except:
                        pass
                    print("Copying %s dependency from zig global cache to project local build deps, hash: %s" % (dep_name, dep_hash))
                    await async fs.copytree(src, dst)
            else:
                raise ValueError("Dependency %s has no hash or path set" % dep_name)
        build_deps()

    def on_zig_fetch_error(errmsg):
        print(errmsg, err=True)
        env.exit(1)

    def check_for_buildconfig():
        """Check if dependencies.json exists

        If there is a dependencies.json file, we will read it and check if the
        dependencies also exist locally. If not, we will download them and
        proceed to build the dependencies and then build the project.

        If there is no dependencies.json file, we will build the project.
        """
        try:
            build_config = BuildConfig.from_json(file.ReadFile(rfcap, "build.act.json").read().decode())
        except FileNotFoundError:
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            env.exit(1)
            return

        build_config_fetchable = BuildConfig()
        for dep_name, dep in build_config.dependencies.items():
            if dep_name in dep_path_overrides:
                dep_path = dep_path_overrides[dep_name]
                # Zig wants relative paths
                rel_path = file.get_relative_path(dep_path, fs.cwd())
                dep.path = rel_path
                print("INFO: Using dependency path %s for %s" % (rel_path, dep.name), err=True)
            else:
                build_config_fetchable.dependencies[dep_name] = dep

        for dep_name, dep in build_config.zig_dependencies.items():
            build_config_fetchable.zig_dependencies[dep_name] = dep

        for dep_name, dep in build_config.dependencies.items():
            print("Dependency:", dep_name, dep.path)

        write_buildzig(file.FileCap(env.cap), build_config)
        zfd = ZigFetchDeps(env, build_config_fetchable, lambda x, y: check_deps(), on_zig_fetch_error)

    def get_lock():
        """Try to get the build lock for the project
        """
        try:
            lock_file = file.WriteFile(file.WriteFileCap(fcap), ".acton.lock", lock=True)
            check_for_buildconfig()
        except OSError:
            print("Build lock exists, trying again soon...")
            after 1: get_lock()

    # check cache size and warn or clean if necessary...
    warn_on_large_zig_global_cache(file.FileCap(env.cap))
    clean_zig_local_cache(file.FileCap(env.cap))
    # and off we go! Start by grabbing the project build lock
    get_lock()


actor RunModuleTest(process_cap, modname, test_cmd, on_json_output, on_test_error):
    var stdout_buf = b""
    var stderr_buf = b""
    var errout = ""
    var likely_json = False

    def on_stdout(p, data: bytes):
        stdout_buf += data

    def on_stderr(p, data):
        if not likely_json:
            if data.startswith(b"{"):
                likely_json = True
        stderr_buf += data
        lines = stderr_buf.splitlines(True)
        stderr_buf = b""
        for line in lines:
            if likely_json:
                if line.endswith(b"\n"):
                    # valid line
                    try:
                        upd = json.decode(line.decode())
                    except ValueError:
                        pass
                    else:
                        on_json_output(upd)
                else:
                    # incomplete line
                    stderr_buf = line
                    break
            if not likely_json:
                errout += line.decode()


    def on_exit(p, exit_code, term_signal):
        if exit_code != 0 or term_signal != 0:
            on_test_error(exit_code, term_signal, stdout_buf.decode() + errout)

    def on_error(p, error):
        on_test_error(-1, -1, error)

    # TODO: fs.join()
    cmd = ["out/bin/.test_" + modname, "--json"] + test_cmd
    p = process.Process(process_cap, cmd, on_stdout, on_stderr, on_exit, on_error)


actor RunTestList(env, args):
    """Print list of module tests

    Will run the project module test binaries with 'list --json' to get all
    module tests, collect the output and print a list of all project tests.
    """
    process_cap = process.ProcessCap(env.cap)
    var _expected_modules: set[str] = set()
    var _module_tests = {}

    def print_module_tests():
        for mn in _module_tests.keys():
            print("Module %s:" % mn)
            for module_test_name in _module_tests[mn]:
                print(" ", module_test_name)
            print()

    def _on_json_output(module_name, update):
        if module_name in _module_tests:
            raise ValueError("Duplicate list of tests from module: " + module_name)
        if isinstance(update, dict):
            _module_tests[module_name] = []
            update_tests = update["tests"]
            if isinstance(update_tests, dict):
                for test in update_tests.values():
                    _module_tests[module_name].append(test["definition"]["name"])
        else:
            raise ValueError("Unexpected JSON data from module test: " + module_name)

        if set(_module_tests.keys()) == _expected_modules:
            print_module_tests()
            env.exit(0)

    def _on_test_error(exit_code, term_signal, stderr_buf):
        pass

    def _run_tests(module_names: list[str]):
        _expected_modules = set(module_names)

        for module_name in module_names:
            t = RunModuleTest(process_cap, module_name, ["list", "--modname", module_name], lambda x: _on_json_output(module_name, x), _on_test_error)

    def _on_build_success(stdout_buf: str):
        test_modules = []
        stdout_tests = False
        for line in stdout_buf.splitlines(False):
            if line.startswith("Test executables:"):
                stdout_tests = True
            else:
                if stdout_tests:
                    test_modules.append(line)
        _run_tests(test_modules)

    def _on_build_failure(exit_code, term_signal, stderr_buf: str):
        print("Failed to build project tests")
        print("actonc exited with code %d / %d" % (exit_code, term_signal))
        print("stderr:", stderr_buf)
        env.exit(1)

    project_builder = BuildProject(
        process_cap,
        env,
        args,
        _on_build_success,
        _on_build_failure,
        build_tests=True
    )


actor RunTestTest(env: Env, args, perf_mode: bool=False):
    process_cap = process.ProcessCap(env.cap)
    var expected_modules_list: set[str] = set()
    var _module_tests = {}
    var modules_to_test = set()
    var perf_data = "{}"
    fs = file.FS(file.FileCap(env.cap))

    test_cmd_args = []
    for name_filter in args.get_strlist("name"):
        test_cmd_args.extend(["--name", name_filter])

    try:
        perf_file = file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "perf_data")
        perf_data = perf_file.read().decode()
    except:
        pass
    ptr = testing.ProjectTestResults(perf_data, perf_mode)

    def _periodic_show():
        r = ptr.show(only_show_complete=not env.is_tty())
        if r is not None:
            if args.get_bool("record"):
                perf_wfile = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "perf_data")
                perf_wfile.write(ptr.to_json().encode())
                perf_wfile.close()
            if args.get_bool("golden-update"):
                for module_name, tests in ptr.results.items():
                    for test_name, test_info in tests.items():
                        exc = test_info.exception
                        output = test_info.output
                        if exc is not None and output is not None and exc.startswith("testing.NotEqualError: Test output does not match expected golden value"):
                            rpath = ["test", "golden", module_name]
                            filename = file.join_path([fs.cwd()] + rpath + [test_name])
                            for idx in range(1, len(rpath)+1):
                                mkdir_path = file.join_path([fs.cwd()] + rpath[0:idx])
                                try:
                                    a = fs.mkdir(mkdir_path)
                                except:
                                    pass
                            golden_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), filename)
                            golden_file.write(output.encode())
                            await async golden_file.close()

            env.exit(r)
            return
        after 0.05: _periodic_show()

    def _on_json_output(module_name, data):
        if isinstance(data, dict):
            if "tests" in data:
                data_tests = data["tests"]
                tests = {}
                for test_name, json_test_info in data_tests.items():
                    if isinstance(json_test_info, dict):
                        tests[test_name] = TestInfo.from_json(json_test_info)

                ptr.update_module(module_name, tests)
                expected_modules_list.discard(module_name)
                if len(expected_modules_list) == 0:
                    # We have received the test list from all modules, show
                    # results to get empty skeleton and then run tests.
                    # NOTE: in perf mode we run a single module at a time and
                    # that module in turn limits concurrency to 1
                    _periodic_show()
                    _run_module_tests(run_all=not perf_mode)

            elif "test_info" in data:
                test_info = TestInfo.from_json(data["test_info"])
                ptr.update(module_name, test_info.definition.name, test_info)
                if ptr.is_module_done(module_name) and perf_mode:
                    _run_module_tests()
        else:
            raise ValueError("Unexpected JSON data from module test: " + module_name)

    def _on_test_error(module_name: str, exit_code: int, term_signal: int, errout: str):
        errmsg = "Module test error, exit_code %d and term signal %d, errout: " % (exit_code, term_signal)
        try:
            errmsg += errout
        except IndexError:
            pass
        if module_name in ptr.results:
            moderr = testing.ModuleError(exit_code, term_signal, errout)
            ptr.update_module_error(module_name, moderr)
        _run_module_tests()

    def _run_tests(module_names: list[str]):
        select_modules = set(args.get_strlist("module"))
        if len(select_modules) > 0:
            for module_name in module_names:
                if module_name in select_modules:
                    modules_to_test.add(module_name)
        else:
            modules_to_test = set(module_names)
        expected_modules_list = set(modules_to_test)
        ptr.expected_modules = set(modules_to_test)
        if len(modules_to_test) == 0:
            print("No tests found")
            env.exit(0)
            return

        # List all tests first, which we can run in parallel. Once we have the
        # list of all tests we can start running them one at a time in sequence.
        for module_name in modules_to_test:
            t = RunModuleTest(process_cap, module_name, ["list", "--modname", module_name] + test_cmd_args, lambda x: _on_json_output(module_name, x), lambda x, y, z: _on_test_error(module_name, x, y, z))

    def _run_module_tests(run_all=False):
        try:
            module_name = modules_to_test.pop()
            cmd = ["test"]
            if perf_mode:
                cmd += ["perf"]
            cmd += ["--modname", module_name]
            cmd += test_cmd_args
            t = RunModuleTest(process_cap, module_name, cmd, lambda x: _on_json_output(module_name, x), lambda x, y, z: _on_test_error(module_name, x, y, z))
        except ValueError:
            _periodic_show()
            return
        if run_all:
            _run_module_tests(run_all)

    def _on_build_success(stdout_buf: str):
        print(term.clearline + term.up() + term.clearline, end="")
        test_modules = []
        stdout_tests = False
        for line in stdout_buf.splitlines(False):
            if line.startswith("Test executables:"):
                stdout_tests = True
            else:
                if stdout_tests:
                    test_modules.append(line)
        _run_tests(test_modules)

    def _on_build_failure(exit_code, term_signal, stderr_buf: str):
        print("Failed to build project tests")
        print("actonc exited with code %d / %d" % (exit_code, term_signal))
        print("stderr:", stderr_buf)
        env.exit(1)

    # TODO: let dev mode enable for normal test and disable, i.e. use release mode for perf tests
    # However, we have some stability issue due to wonky compilation
    # optimizations so we get crashes. Thus we now always run in dev mode to get
    # actually working code.
    #dev = not perf_mode
    dev = True
    print("Building project tests...")
    project_builder = BuildProject(process_cap, env, args, _on_build_success, _on_build_failure, build_tests=True)

def build_cmd_args(args):
    cmdargs = []
    for argname, arg in args.options.items():
        # TODO: reverse this logic, we should only pass in a small set of options, not all
        if argname in {"file", "record", "golden-update"}:
            continue
        if arg.type == "bool":
            if args.get_bool(argname):
                cmdargs.append("--" + argname)
        elif arg.type == "str":
            if args.get_str(argname) != '':
                cmdargs.append("--" + argname)
                cmdargs.append(args.get_str(argname))
        elif arg.type == "int":
            if args.get_int(argname) != 0:
                cmdargs.append("--" + argname)
                cmdargs.append(str(args.get_int(argname)))

    return cmdargs


actor ZigFetchDeps(env, build_config: BuildConfig, on_done: action(int, int) -> None, on_fetch_error: action(str) -> None, print_output: bool=False):
    """Fetch dependencies and Zig dependencies
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))
    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    remaining_deps = {}

    dep_processes = {}
    zig_processes = {}
    var total = 0
    var fetched = 0

    def on_exit(dep: Dependency, p, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            fetched_hash: str = stdout_buf.decode().strip()
            if print_output:
                print("Fetched dependency %s with hash %s" % (dep.name, fetched_hash), err=True)

            dep_hash = dep.hash
            if dep_hash is not None:
                if dep_hash != fetched_hash:
                    errmsg = "ERROR: hash mismatch for dependency %s" % dep.name
                    errmsg += "\nDETAIL: fetched hash (%s) differs from configured hash (%s)" % (fetched_hash, dep_hash)
                    errmsg += "\nHINT: Update build.act.json with the correct hash. Prefer immutable URLs, like a ref to an immutable git tag over a mutable git branch."
                    on_fetch_error(errmsg)
                    return

            fetched += 1
            if isinstance(dep, PkgDependency):
                del dep_processes[dep.name]
            elif isinstance(dep, ZigDependency):
                del zig_processes[dep.name]

            if len(dep_processes) == 0 and len(zig_processes) == 0:
                on_done(total, fetched)
        else:
            on_fetch_error(stderr_buf.decode())

    def on_error(dep, p, error):
        # TODO: collect all errors before calling on_fetch_error?
        on_fetch_error(error)

    zig_global_cache_dir = get_zig_global_cache_dir(file.FileCap(env.cap))
    for dep_name, dep in build_config.dependencies.items():
        total += 1
        dep_path = dep.path
        if dep_path is not None:
            if print_output:
                print("Skip fetching dependency %s that uses local path (%s)" % (dep.name, dep_path))
            continue

        dep_url = dep.url
        dep_hash = dep.hash
        if dep_url is not None:
            if dep_hash is not None:
                dep_dir = file.join_path([zig_global_cache_dir, "p", dep_hash])
                try:
                    s = fs.stat(dep_dir)
                    continue
                except:
                    pass
            else:
                on_fetch_error("dependency %s does not have a hash configured")

            cmd = [zig, "fetch", "--global-cache-dir", zig_global_cache_dir, dep_url]
            p = process.RunProcess(
                pcap,
                cmd,
                lambda p, exit_code, term_signal, stdout_buf, stderr_buf: on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf),
                lambda p, error: on_error(dep, p, error))
            dep_processes[dep.name] = p

    for dep_name, dep in build_config.zig_dependencies.items():
        total += 1
        dep_path = dep.path
        if dep_path is not None:
            if print_output:
                print("Skip fetching dependency %s that uses local path (%s)" % (dep.name, dep_path))
            continue

        dep_url = dep.url
        dep_hash = dep.hash
        if dep_url is not None:
            if dep_hash is not None:
                dep_dir = file.join_path([zig_global_cache_dir, "p", dep_hash])
                try:
                    s = fs.stat(dep_dir)
                    continue
                except:
                    pass
            else:
                on_fetch_error("dependency %s does not have a hash configured")

            cmd = [zig, "fetch", "--global-cache-dir", zig_global_cache_dir, dep_url]
            p = process.RunProcess(
                pcap,
                cmd,
                lambda p, exit_code, term_signal, stdout_buf, stderr_buf: on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf),
                lambda p, error: on_error(dep, p, error))
            zig_processes[dep.name] = p

    if len(dep_processes) == 0 and len(zig_processes) == 0:
        on_done(total, fetched)


actor CmdFetch(env, args):
    pcap = process.ProcessCap(env.cap)
    fcap = file.FileCap(env.cap)
    rfcap = file.ReadFileCap(fcap)
    fs = file.FS(file.FileCap(env.cap))
    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    remaining_deps = {}


    dep_processes = {}
    zig_processes = {}

    def all_done(total, fetched):
        if total == 0:
            print("No dependencies to fetch", err=True)
        else:
            print("All dependencies up to date", err=True)
        env.exit(0)

    def on_zig_fetch_error(errmsg):
        print(errmsg, err=True)
        env.exit(1)

    def _read_build_config():
        try:
            build_config = BuildConfig.from_json(file.ReadFile(rfcap, "build.act.json").read().decode())
            write_buildzig(file.FileCap(env.cap), build_config)
            zfd = ZigFetchDeps(env, build_config, all_done, on_zig_fetch_error, print_output=True)
        except FileNotFoundError:
            print("No build.act.json file found, nothing to do.")
            env.exit(0)
            return
        except ValueError as e:
            print("ERROR:", e.error_message)
            env.exit(1)
            return


actor CmdPkgAdd(env, args):
    """Add a package dependency to the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    # What arguments do we need?
    # - the name of the dependency (e.g. "foo", used in the build.act.json config file)
    # - the URL to fetch it from

    # We need to fetch the dependency and get the (content) hash of the fetched
    # dependency and store it in the build.act.json file. If the dependency is
    # already in the build.act.json file, we need to check if the hash is the
    # same as the one we just fetched. If it is, we do nothing. If it is not,

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)
    dep_url = args.get_str("url")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except FileNotFoundError:
            # Ignore, we create a new file
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            await async env.exit(1)
        return BuildConfig()

    build_config = get_build_config()

    def on_exit(p, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            dep_hash = stdout_buf.decode().strip()

            if dep_name in build_config.dependencies:
                bc_dep = build_config.dependencies[dep_name]
                if bc_dep.url != dep_url:
                    print("Updated existing dependency", dep_name, "with new URL", dep_url, " (old", bc_dep.url, ")")
                    bc_dep.url = dep_url
                if bc_dep.hash == dep_hash:
                    print("Dependency", dep_name, "is already up to date, hash:", dep_hash)
                else:
                    print("Updated existing dependency", dep_name, "with new hash", dep_hash, " (old", bc_dep.hash, ")")
                    bc_dep.hash = dep_hash
            else:
                # Add the hash
                build_config.dependencies[dep_name] = PkgDependency(dep_name, dep_url, dep_hash)
                print("Added new package dependency", dep_name, "with hash", dep_hash)

            baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
            baj_file.write(build_config.to_json().encode()+b"\n")
            await async baj_file.close()

            env.exit(0)
        else:
            print("Error fetching", stderr_buf.decode())
            env.exit(1)

    def on_error(p, error):
        print("Error fetching", error)
        env.exit(1)

    cmd = [zig, "fetch", "--global-cache-dir", get_zig_global_cache_dir(file.FileCap(env.cap)), args.get_str("url")]
    process.RunProcess(
        pcap,
        cmd,
        on_exit,
        on_error)


actor CmdPkgRemove(env, args):
    """Remove a package dependency from the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except FileNotFoundError:
            # Ignore, we create a new file
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            await async env.exit(1)
        return BuildConfig()

    build_config = get_build_config()

    if dep_name in build_config.dependencies:
        print("Removed package dependency", dep_name)
        del build_config.dependencies[dep_name]
    else:
        print("Dependency", dep_name, "not found in build.act.json. Nothing to do.")

    baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
    baj_file.write(build_config.to_json().encode()+b"\n")
    await async baj_file.close()

    env.exit(0)


actor CmdZigPkgAdd(env, args):
    """Add a zig package dependency to the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    # What arguments do we need?
    # - the name of the dependency (e.g. "foo", used in the build.act.json config file)
    # - the URL to fetch it from

    # We need to fetch the dependency and get the (content) hash of the fetched
    # dependency and store it in the build.act.json file. If the dependency is
    # already in the build.act.json file, we need to check if the hash is the
    # same as the one we just fetched. If it is, we do nothing. If it is not,

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)
    dep_url = args.get_str("url")
    dep_artifacts = args.get_strlist("artifact")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except FileNotFoundError:
            # Ignore, we create a new file
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            await async env.exit(1)
        return BuildConfig()

    build_config = get_build_config()

    def on_exit(p, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            dep_hash = stdout_buf.decode().strip()

            if dep_name in build_config.zig_dependencies:
                if build_config.zig_dependencies[dep_name].url != dep_url:
                    print("Updated existing dependency", dep_name, "with new URL", dep_url, " (old", build_config.zig_dependencies[dep_name].url, ")")
                    build_config.zig_dependencies[dep_name].url = dep_url

                if build_config.zig_dependencies[dep_name].hash == dep_hash:
                    print("Dependency", dep_name, "is already up to date, hash:", dep_hash)
                else:
                    print("Updated existing dependency", dep_name, "with new hash", dep_hash, " (old", build_config.zig_dependencies[dep_name].hash, ")")
                    build_config.zig_dependencies[dep_name].hash = dep_hash
            else:
                # Add the hash
                build_config.zig_dependencies[dep_name] = ZigDependency(dep_name, dep_url, dep_hash, None, {}, dep_artifacts)
                print("Added new Zig package dependency", dep_name, "with hash", dep_hash)

            baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
            baj_file.write(build_config.to_json().encode()+b"\n")
            await async baj_file.close()

            env.exit(0)
        else:
            print("Error fetching", stderr_buf.decode())
            env.exit(1)

    def on_error(p, error):
        print("Error fetching", error)
        env.exit(1)

    cmd = [zig, "fetch", "--global-cache-dir", get_zig_global_cache_dir(file.FileCap(env.cap)), args.get_str("url")]
    process.RunProcess(
        pcap,
        cmd,
        on_exit,
        on_error)


actor CmdZigPkgRemove(env, args):
    """Remove a package dependency from the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)

    def _get_build_config():
        try:
            build_config = BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
            _remove_zig_pkg(build_config, dep_name)
        except FileNotFoundError:
            # Ignore, we create a new file
            print("No build.act.json file found, nothing to do.")
            env.exit(0)
        except ValueError as e:
            print("ERROR:", e.error_message)
            env.exit(1)

    def _remove_zig_pkg(build_config, dep_name):
        if dep_name in build_config.zig_dependencies:
            print("Removed Zig package dependency", dep_name)
            del build_config.zig_dependencies[dep_name]
        else:
            print("Zig dependency", dep_name, "not found in build.act.json. Nothing to do.")

        baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
        baj_file.write(build_config.to_json().encode()+b"\n")
        await async baj_file.close()

        env.exit(0)

    _get_build_config()


actor main(env):
    file_cap = file.FileCap(env.cap)
    process_cap = process.ProcessCap(env.cap)

    def in_project(filename: str):
        """Are we in a project?
        """
        fs = file.FS(file_cap)
        try:
            s = fs.stat("Acton.toml")
        except:
            return False
        return True

    def _compilefile(_file, args):
        if in_project(_file):
            def on_build_success(stdout_buf):
                env.exit(0)

            def on_build_failure(exit_code: int,  term_signal: int, stderr_buf: str):
                print("Error building project", stderr_buf)
                env.exit(1)

            BuildProject(process_cap, env, args, on_build_success, on_build_failure, build_tests=False, files=[_file])
        else:
            cmdargs = build_cmd_args(args)
            cr = CompilerRunner(process_cap, env, [_file] + cmdargs)

    def _cmd_build(args):
        def on_build_success(stdout_buf):
            env.exit(0)

        def on_build_failure(exit_code: int,  term_signal: int, stderr_buf: str):
            print("Error building project", stderr_buf)
            env.exit(1)

        BuildProject(process_cap, env, args, on_build_success, on_build_failure, build_tests=False)

    def _cmd_doc(args):
        env.exit(0)

    def _cmd_fetch(args):
        c = CmdFetch(env, args)

    def _cmd_pkg(args):
        env.exit(0)

    def _cmd_pkg_add(args):
        c = CmdPkgAdd(env, args)

    def _cmd_pkg_rm(args):
        c = CmdPkgRemove(env, args)

    def _cmd_new(args):
        cr = CompilerRunner(process_cap, env, ["new", args.get_str("projectdir")])
        env.exit(0)

    def _cmd_test(args):
        run_tests = RunTestTest(env, args, perf_mode=False)

    def _cmd_test_perf(args):
        run_tests = RunTestTest(env, args, perf_mode=True)

    def _cmd_list_test(args):
        run_tests = RunTestList(env, args)

    def _cmd_version(args):
        if args.get_bool("full"):
            CompilerRunner(process_cap, env, ["--version"])
        else:
            CompilerRunner(process_cap, env, ["--numeric-version"])

    def _cmd_zigpkg(args):
        env.exit(0)

    def _cmd_zigpkg_add(args):
        c = CmdZigPkgAdd(env, args)

    def _cmd_zigpkg_rm(args):
        c = CmdZigPkgRemove(env, args)

    def _parse_args():
        p = argparse.Parser()
        p.add_bool("always-build", "Always build")
        p.add_bool("parse", "Show parsing result")
        p.add_bool("kinds", "Show results after kind checking")
        p.add_bool("types", "Show inferred expression types")
        p.add_bool("sigs", "Show inferred type signatures")
        p.add_bool("norm", "Show results after syntactic normalization")
        p.add_bool("deact", "Show results after deactorization")
        p.add_bool("cps", "Show results after CPS conversion")
        p.add_bool("llift", "Show results of lambda lifting")
        p.add_bool("hgen", "Show generated .h header")
        p.add_bool("cgen", "Show generated .c code")
        p.add_bool("ccmd", "Show CC / LD command lines")
        p.add_bool("timing", "Show timing information")
        p.add_bool("auto-stub", "Allow automatica stub detection")
        p.add_bool("stub", "Stub (.ty) file generation only")
        p.add_bool("cpedantic", "Pedantic C compilation")
        p.add_bool("quiet", "Be quiet")
        p.add_bool("debug", "Print debug stuff")
        p.add_bool("dev", "Development mode")
        p.add_bool("only-build", "Only perform final build of .c files, do not compile .act files")
        p.add_bool("skip-build", "Skip final build of .c files")
        p.add_bool("keepbuild", "Keep build.zig")
        p.add_option("root", "str", "?", "", "Set root actor")
        p.add_option("tempdir", "str", "?", "", "Directory for temporary build files")
        p.add_option("syspath", "str", "?", "", "syspath")
        p.add_option("target", "str", "?", "", "Target, e.g. x86_64-linux-gnu.2.28")
        p.add_option("dep", "strlist", "+", [], "Override path to dependency, e.g. --dep-path foo=../my-foo-repo")
        p.add_arg("file", ".act file to compile, or .ty to show", False, "?")

        p_build = p.add_cmd("build", "Build", _cmd_build)

        p_fetch = p.add_cmd("fetch", "Fetch all the things for offline work", _cmd_fetch)

        p_pkg = p.add_cmd("pkg", "Manage package dependencies", _cmd_pkg)

        p_pkg_add = p_pkg.add_cmd("add", "Add package dependency", _cmd_pkg_add)
        p_pkg_add.add_arg("url", "URL of dependency", True, "?")
        p_pkg_add.add_arg("name", "Name of dependency", True, "?")
        p_pkg_add.add_option("hash", "str", "?", "", "Hash of dependency")

        p_pkg_rm = p_pkg.add_cmd("remove", "Remove package dependency", _cmd_pkg_rm)
        p_pkg_rm.add_arg("name", "Name of dependency", True, "?")

        docp = p.add_cmd("doc", "Show documentation", _cmd_doc)

        newp = p.add_cmd("new", "New project", _cmd_new)
        newp.add_arg("projectdir", "Project directory", True, "?")

        testp = p.add_cmd("test", "Test", _cmd_test)
        testp.add_bool("record", "Record test performance results")
        testp.add_bool("golden-update", "Update expected golden values based on current values")
        testp.add_option("module", "strlist", "+", [], "Filter on test module name")
        testp.add_option("name", "strlist", "+", [], "Filter on test name")

        testlistp = testp.add_cmd("list", "List tests", _cmd_list_test)

        testperfp = testp.add_cmd("perf", "Perf", _cmd_test_perf)

        version_p = p.add_cmd("version", "Show version", _cmd_version)
        version_p.add_bool("full", "Show full version info")

        p_zigpkg = p.add_cmd("zig-pkg", "Manage Zig package dependencies", _cmd_zigpkg)

        p_zigpkg_add = p_zigpkg.add_cmd("add", "Add Zig package dependency", _cmd_zigpkg_add)
        p_zigpkg_add.add_arg("url", "URL of dependency", True, "?")
        p_zigpkg_add.add_arg("name", "Name of dependency", True, "?")
        p_zigpkg_add.add_option("hash", "str", "?", "", "Hash of dependency")
        p_zigpkg_add.add_option("artifact", "strlist", "+", [], "Library artifact to link with")

        p_zigpkg_rm = p_zigpkg.add_cmd("remove", "Remove Zig package dependency", _cmd_zigpkg_rm)
        p_zigpkg_rm.add_arg("name", "Name of dependency", True, "?")

        return p.parse(env.argv)

    try:
        _args = _parse_args()
        _cmd = _args.cmd
        _file = None
        try:
            _file = _args.get_str("file")
        except argparse.ArgumentError:
            pass
        if _cmd is not None:
            if _file is not None and (_file.endswith(".act") or _file.endswith(".ty")):
                print("Error: cannot specify both a command and an .act/.ty file", err=True)
                await async env.exit(1)
            _cmd(_args)
        else:
            if _file is not None:
                _compilefile(_file, _args)
            else:
                env.exit(0)
    except argparse.PrintUsage as exc:
        print(exc.error_message)
        env.exit(0)
    except argparse.ArgumentError as exc:
        print(exc.error_message)
        env.exit(1)
