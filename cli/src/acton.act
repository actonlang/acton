import argparse
import file
import json
import process
import testing

from buildy import *
from testing import TestInfo

def base_path(file_cap: file.FileCap):
    fs = file.FS(file_cap)
    return fs.exepath()[0:-len("/bin/acton")]

def clean_buildcache(cap: file.FileCap):
    fs = file.FS(cap)
    cache_dir = fs.homedir() + "/.cache/acton"
    #cache_dir = fs.join(fs.homedir(), ".cache", "acton")
    total_size = 0
    for f in fs.walk(cache_dir):
        total_size += f.size
    if total_size > 15 * 1024 * 1024 * 1024: # 5GB
        print("Build cache (", total_size // (1024*1024), "MB) over 5GB, cleaning it up.")
        fs.rmtree(cache_dir)
        total_size = 0
    if total_size == 0:
        print("Acton build cache is empty: rebuilding Acton base from source, which might take a while...")

def write_buildzig(file_cap, build_config: BuildConfig):
    fs = file.FS(file_cap)

    def get_build_zig_templates():
        # Read the build.zig template
        build_zig_template = file.ReadFile(
            file.ReadFileCap(file_cap),
            file.join_path([base_path(file_cap), "builder", "build.zig"])).read().decode()
        build_zig_zon_template = file.ReadFile(
            file.ReadFileCap(file_cap),
            file.join_path([base_path(file_cap), "builder", "build.zig.zon"])).read().decode()
        return build_zig_template, build_zig_zon_template

    build_zig_tpl, build_zig_zon_tpl = get_build_zig_templates()
    # Write build.zig
    b_file = file.WriteFile(file.WriteFileCap(file_cap), "build.zig")
    await async b_file.write(gen_buildzig(build_zig_tpl, build_config).encode())
    await async b_file.close()
    # Write build.zig.zon
    bzz_file = file.WriteFile(file.WriteFileCap(file_cap), "build.zig.zon")
    await async bzz_file.write(gen_buildzigzon(build_zig_zon_tpl, build_config).encode())
    await async bzz_file.close()


actor CompilerRunner(process_cap, env, args, wdir=None, on_exit: ?action(int, int, bytes, bytes) -> None=None, on_error: ?action(str) -> None=None, print_output: bool=True, exe="actonc"):
    """Run the actonc compiler

    Will run actonc with the provided command and arguments. It is possible to
    inject callbacks when actonc exits or encounters an error. If no callbacks
    are provided, the default behavior is to exit when actonc does, possibly
    with an error message. Similarly, if actonc encounters an error, it will
    print the error message and exit.
    """
    var stdout_buf = b""
    var stderr_buf = b""

    def on_actonc_stderr(p, data):
        stderr_buf += data
        if print_output:
            print(data.decode(), end="")

    def on_actonc_stdout(p, data):
        stdout_buf += data
        if print_output:
            print(data.decode(), end="")

    def on_actonc_exit(p, exit_code, term_signal):
        if on_exit is not None:
            on_exit(exit_code, term_signal, stdout_buf, stderr_buf)
        else:
            if exit_code != 0:
                print("actonc exited with code: ", exit_code, " terminated with signal:", term_signal)
            env.exit(exit_code)

    def on_actonc_error(p, error: str):
        if on_error is not None:
            on_error(error)
        else:
            print("Error from process:", error)
            env.exit(1)

    clean_buildcache(file.FileCap(env.cap))
    fs = file.FS(file.FileCap(env.cap))
    # We find the path to actonc by looking at the executable path of the
    # current process. Since we are called 'acton', we just add a 'c'.
    cmd = [fs.exepath() + ("c" if exe == "actonc" else "")] + args
    p = process.Process(process_cap, cmd, on_actonc_stdout, on_actonc_stderr, on_actonc_exit, on_actonc_error, wdir)


actor BuildProject(process_cap, env, args, on_build_success: action(str) -> None, on_build_failure: action(int, int, str) -> None, build_tests: bool=False):
    """Build the project including dependencies

    - check for dependencies.json, if found, download dependencies
    - build dependencies
    - build
    """
    fcap = file.FileCap(env.cap)
    rfcap = file.ReadFileCap(fcap)
    fs = file.FS(fcap)
    lock_file = None
    remaining_deps = {}
    cmdargs = ["build"] + build_cmd_args(args)
    if build_tests:
        cmdargs.append("--dev")
        cmdargs.append("--test")
    var build_config = BuildConfig()
    #

    def _on_actonc_exit(exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            on_build_success(stdout_buf.decode())
        else:
            on_build_failure(exit_code, term_signal, stdout_buf.decode() + stderr_buf.decode())

    def _on_actonc_failure(error: str):
        on_build_failure(-999, -999, error)

    def build_project():
        search_paths = []
        for dep_name, dep in build_config.dependencies.items():
            hash = dep.hash
            path = dep.path
            if hash is not None:
                search_paths.append(file.join_path([fs.homedir(), ".cache", "acton", "build-cache", "p", hash, "out", "types"]))
            elif path is not None:
                # deconstruct and put together to get OS independent path? i.e. flip / to \ on windows
                # TODO: force relative path?
                search_paths.append(path)
            else:
                raise ValueError("Dependency %s has no hash" % dep_name)
        search_path_arg = []
        for sp in search_paths:
            search_path_arg.extend(["--searchpath", sp])
        cr = CompilerRunner(process_cap,
            env,
            cmdargs + ["--deppath", file.join_path([fs.cwd(), "deps"])] + search_path_arg,
            None,
            _on_actonc_exit,
            _on_actonc_failure,
            print_output=not build_tests
        )

    def _on_dep_actonc_exit(dep_name, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            print("Dependency", dep_name, "built successfully")
            try:
                del remaining_deps[dep_name]
            except KeyError:
                pass

            if len(remaining_deps) == 0:
                print("All dependencies built, building main project")
                build_project()
        else:
            # TODO: do better
            raise ValueError("Error building dependency")


    def on_dep_build_error(name, error):
        print("Error building dependency", name, error)

    def build_deps():
        # Find dependencies and compile them first
        deps = []
        try:
            deps = fs.listdir("deps")
        except OSError:
            pass

        if len(deps) == 0:
            build_project()
        else:
            print("Building dependencies:")
            for dep_name in deps:
                print(" -", dep_name)
                remaining_deps[dep_name] = True
                cr = CompilerRunner(
                    process_cap,
                    env,
                    cmdargs + ["--keepbuild"],
                    file.join_path(["deps", dep_name]),
                    lambda exit_code, term_signal, stdout_buf, stderr_buf: _on_dep_actonc_exit(dep_name, exit_code, term_signal, stdout_buf, stderr_buf),
                    lambda error_msg: on_dep_build_error(dep_name, error_msg),
                    exe="acton"
                )

    def check_deps():
        # 1. fetch dependencies (into zig global cache)
        # 2. copy dependencies from zig global cache to deps/
        # 3. build dependencies
        # 4. build project
        deps_dir = set()
        try:
            deps_dir = set(fs.listdir("deps"))
        except OSError:
            fs.mkdir("deps")

        for dep_name, dep in build_config.dependencies.items():
            # Does deps/X exist?
            hash = dep.hash
            path = dep.path
            if hash is not None:
                if dep_name not in deps_dir:
                    print("Copying", dep_name, "from zig global cache")
                    fs.mkdir(file.join_path(["deps", dep_name]))
                    src = file.join_path([fs.homedir(), ".cache", "acton", "build-cache", "p", hash])
                    dst = file.join_path([fs.cwd(), "deps", dep_name])
                    print("Copying", src, "to", dst)
                    await async fs.copytree(src, dst)
            elif path is not None:
                pass
            else:
                raise ValueError("Dependency %s has no hash" % dep_name)
        build_deps()

    def on_zig_fetch_error(error):
        print("Error fetching dependencies", error)
        env.exit(1)

    def check_for_buildconfig():
        """Check if dependencies.json exists

        If there is a dependencies.json file, we will read it and check if the
        dependencies also exist locally. If not, we will download them and
        proceed to build the dependencies and then build the project.

        If there is no dependencies.json file, we will build the project.
        """
        def read_buildconfig():
            f = file.ReadFile(rfcap, "build.act.json")
            conf = f.read()
            return BuildConfig.from_json(conf.decode())

        try:
            build_config = read_buildconfig()
        except FileNotFoundError:
            pass

        write_buildzig(file.FileCap(env.cap), build_config)
        ZigFetchDeps(env, build_config, check_deps, on_zig_fetch_error)

    def get_lock():
        """Try to get the build lock for the project
        """
        try:
            lock_file = file.WriteFile(file.WriteFileCap(fcap), ".acton.lock", lock=True)
            check_for_buildconfig()
        except OSError:
            print("Build lock exists, trying again soon...")
            after 1: get_lock()

    # and off we go! Start by grabbing the project build lock
    get_lock()


actor RunModuleTest(process_cap, modname, test_cmd, on_json_output, on_test_error):
    var stdout_buf = b""
    var stderr_buf = b""
    var errout = ""
    var likely_json = False

    def on_stdout(p, data: bytes):
        stdout_buf += data

    def on_stderr(p, data):
        if not likely_json:
            if data.startswith(b"{"):
                likely_json = True
        stderr_buf += data
        lines = stderr_buf.splitlines(True)
        stderr_buf = b""
        for line in lines:
            if likely_json:
                if line.endswith(b"\n"):
                    # valid line
                    try:
                        upd = json.decode(line.decode())
                    except ValueError:
                        pass
                    else:
                        on_json_output(upd)
                else:
                    # incomplete line
                    stderr_buf = line
                    break
            if not likely_json:
                errout += line.decode()


    def on_exit(p, exit_code, term_signal):
        if exit_code != 0 or term_signal != 0:
            on_test_error(exit_code, term_signal, stdout_buf.decode() + errout)

    def on_error(p, error):
        on_test_error(-1, -1, error)

    # TODO: fs.join()
    cmd = ["out/bin/.test_" + modname, "--json"] + test_cmd
    p = process.Process(process_cap, cmd, on_stdout, on_stderr, on_exit, on_error)


actor RunTestList(env, args):
    """Print list of module tests

    Will run the project module test binaries with 'list --json' to get all
    module tests, collect the output and print a list of all project tests.
    """
    process_cap = process.ProcessCap(env.cap)
    var _expected_modules: set[str] = set()
    var _module_tests = {}

    def print_module_tests():
        for mn in _module_tests.keys():
            print("Module %s:" % mn)
            for module_test_name in _module_tests[mn]:
                print(" ", module_test_name)
            print()

    def _on_json_output(module_name, update):
        if module_name in _module_tests:
            raise ValueError("Duplicate list of tests from module: " + module_name)
        if isinstance(update, dict):
            _module_tests[module_name] = []
            update_tests = update["tests"]
            if isinstance(update_tests, dict):
                for test in update_tests.values():
                    _module_tests[module_name].append(test["definition"]["name"])
        else:
            raise ValueError("Unexpected JSON data from module test: " + module_name)

        if set(_module_tests.keys()) == _expected_modules:
            print_module_tests()
            env.exit(0)

    def _on_test_error(exit_code, term_signal, stderr_buf):
        pass

    def _run_tests(module_names: list[str]):
        _expected_modules = set(module_names)

        for module_name in module_names:
            t = RunModuleTest(process_cap, module_name, ["list"], lambda x: _on_json_output(module_name, x), _on_test_error)

    def _on_build_success(stdout_buf: str):
        test_modules = []
        stdout_tests = False
        for line in stdout_buf.splitlines(False):
            if line.startswith("Test executables:"):
                stdout_tests = True
            else:
                if stdout_tests:
                    test_modules.append(line)
        _run_tests(test_modules)

    def _on_build_failure(exit_code, term_signal, stderr_buf: str):
        print("Failed to build project tests")
        print("actonc exited with code %d / %d" % (exit_code, term_signal))
        print("stderr:", stderr_buf)
        env.exit(1)

    project_builder = BuildProject(
        process_cap,
        env,
        args,
        _on_build_success,
        _on_build_failure,
        build_tests=True
    )


actor RunTestTest(env: Env, args, perf_mode: bool=False):
    process_cap = process.ProcessCap(env.cap)
    var expected_modules_list: set[str] = set()
    var _module_tests = {}
    var modules_to_test = set()
    var perf_data = "{}"

    test_cmd_args = []
    for name_filter in args.get_strlist("name"):
        test_cmd_args.extend(["--name", name_filter])

    try:
        perf_file = file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "perf_data")
        perf_data = perf_file.read().decode()
    except:
        pass
    ptr = testing.ProjectTestResults(perf_data, perf_mode)

    def _periodic_show():
        r = ptr.show(only_show_complete=not env.is_tty())
        if r is not None:
            if args.get_bool("record"):
                perf_wfile = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "perf_data")
                perf_wfile.write(ptr.to_json().encode())
                perf_wfile.close()
            env.exit(r)
        after 0.05: _periodic_show()

    def _on_json_output(module_name, data):
        if isinstance(data, dict):
            if "tests" in data:
                data_tests = data["tests"]
                tests = {}
                for test_name, json_test_info in data_tests.items():
                    if isinstance(json_test_info, dict):
                        tests[test_name] = TestInfo.from_json(json_test_info)

                ptr.update_module(module_name, tests)
                expected_modules_list.discard(module_name)
                if len(expected_modules_list) == 0:
                    _periodic_show()
                    if perf_mode:
                        _run_module_tests()
                    else:
                        # Run all tests in parallel
                        for module_name in modules_to_test:
                            t = RunModuleTest(process_cap, module_name, ["test"] + test_cmd_args, lambda x: _on_json_output(module_name, x), lambda x, y, z: _on_test_error(module_name, x, y, z))

            elif "test_info" in data:
                test_info = TestInfo.from_json(data["test_info"])
                ptr.update(module_name, test_info.definition.name, test_info)
                if ptr.is_module_done(module_name) and perf_mode:
                    _run_module_tests()
        else:
            raise ValueError("Unexpected JSON data from module test: " + module_name)

    def _on_test_error(module_name: str, exit_code: int, term_signal: int, errout: str):
        errmsg = "Module test error, exit_code %d and term signal %d, errout: " % (exit_code, term_signal)
        try:
            errmsg += errout
        except IndexError:
            pass
        if module_name in ptr.results:
            moderr = testing.ModuleError(exit_code, term_signal, errout)
            ptr.update_module_error(module_name, moderr)
        _run_module_tests()

    def _run_tests(module_names: list[str]):
        select_modules = set(args.get_strlist("module"))
        if len(select_modules) > 0:
            for module_name in module_names:
                if module_name in select_modules:
                    modules_to_test.add(module_name)
        else:
            modules_to_test = set(module_names)
        expected_modules_list = set(modules_to_test)
        ptr.expected_modules = set(modules_to_test)
        if len(modules_to_test) == 0:
            print("No tests found")
            env.exit(0)

        # List all tests first, which we can run in parallel. Once we have the
        # list of all tests we can start running them one at a time in sequence.
        for module_name in modules_to_test:
            t = RunModuleTest(process_cap, module_name, ["list"] + test_cmd_args, lambda x: _on_json_output(module_name, x), lambda x, y, z: _on_test_error(module_name, x, y, z))

    def _run_module_tests():
        try:
            module_name = modules_to_test.pop()
            if module_name is not None:
                t = RunModuleTest(process_cap, module_name, ["test", "perf"] + test_cmd_args, lambda x: _on_json_output(module_name, x), lambda x, y, z: _on_test_error(module_name, x, y, z))
            else:
                _periodic_show()
        except:
            pass

    def _on_build_success(stdout_buf: str):
        test_modules = []
        stdout_tests = False
        for line in stdout_buf.splitlines(False):
            if line.startswith("Test executables:"):
                stdout_tests = True
            else:
                if stdout_tests:
                    test_modules.append(line)
        _run_tests(test_modules)

    def _on_build_failure(exit_code, term_signal, stderr_buf: str):
        print("Failed to build project tests")
        print("actonc exited with code %d / %d" % (exit_code, term_signal))
        print("stderr:", stderr_buf)
        env.exit(1)

    # TODO: let dev mode enable for normal test and disable, i.e. use release mode for perf tests
    # However, we have some stability issue due to wonky compilation
    # optimizations so we get crashes. Thus we now always run in dev mode to get
    # actually working code.
    #dev = not perf_mode
    dev = True
    project_builder = BuildProject(process_cap, env, args, _on_build_success, _on_build_failure, build_tests=True)

def build_cmd_args(args):
    cmdargs = []
    for argname, arg in args.options.items():
        if argname in {"file", "record"}:
            continue
        if arg.type == "bool":
            if args.get_bool(argname):
                cmdargs.append("--" + argname)
        elif arg.type == "str":
            if args.get_str(argname) != '':
                cmdargs.append("--" + argname)
                cmdargs.append(args.get_str(argname))
        elif arg.type == "int":
            if args.get_int(argname) != 0:
                cmdargs.append("--" + argname)
                cmdargs.append(str(args.get_int(argname)))

    return cmdargs


actor ZigFetchDeps(env, build_config: BuildConfig, on_done: action() -> None, on_fetch_error: action(str) -> None, print_output: bool=False):
    """Fetch dependencies and Zig dependencies
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))
    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    remaining_deps = {}

    dep_processes = {}
    zig_processes = {}

    def on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            if print_output:
                print("Fetched", stdout_buf.decode())

            if isinstance(dep, Dependency):
                del dep_processes[dep.name]
            elif isinstance(dep, ZigDependency):
                del zig_processes[dep.name]

            if len(dep_processes) == 0 and len(zig_processes) == 0:
                on_done()
        else:
            # TODO: do better
            print("Error fetching", stderr_buf.decode())
            on_fetch_error(stderr_buf.decode())

    def on_error(dep, p, error):
        # TODO: collect all errors before calling on_fetch_error?
        on_fetch_error(error)

    for dep_name, dep in build_config.dependencies.items():
        dep_url = dep.url
        if dep_url is not None:
            cmd = [zig, "fetch", "--global-cache-dir", file.join_path([fs.homedir(), ".cache", "acton", "build-cache"]), dep_url]
            p = process.RunProcess(
                pcap,
                cmd,
                lambda p, exit_code, term_signal, stdout_buf, stderr_buf: on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf),
                lambda p, error: on_error(dep, p, error))
            dep_processes[dep.name] = p

    for dep_name, dep in build_config.zig_dependencies.items():
        dep_url = dep.url
        if dep_url is not None:

            cmd = [zig, "fetch", "--global-cache-dir", file.join_path([fs.homedir(), ".cache", "acton", "build-cache"]), dep_url]
            p = process.RunProcess(
                pcap,
                cmd,
                lambda p, exit_code, term_signal, stdout_buf, stderr_buf: on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf),
                lambda p, error: on_error(dep, p, error))
            zig_processes[dep.name] = p

    if len(dep_processes) == 0 and len(zig_processes) == 0:
        on_done()


actor CmdFetch(env, args):
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))
    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    remaining_deps = {}

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except:
            print("No build.act.json file found, nothing to do.")
            await async env.exit(0)
        return BuildConfig()

    build_config = get_build_config()
    write_buildzig(file.FileCap(env.cap), build_config)

    dep_processes = {}
    zig_processes = {}

    def on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf):
        print("Fetched", stdout_buf.decode())
        if isinstance(dep, Dependency):
            del dep_processes[dep.name]
        elif isinstance(dep, ZigDependency):
            del zig_processes[dep.name]

        if len(dep_processes) == 0 and len(zig_processes) == 0:
            print("All dependencies fetched")
            env.exit(0)

    def on_error(dep, p, error):
        print("Error fetching", error)
        env.exit(1)

    # TODO: call FetchDeps instead!?
    if len(build_config.dependencies) == 0 and len(build_config.zig_dependencies) == 0:
        print("No dependencies to fetch")
        env.exit(0)
    else:
        for dep_name, dep in build_config.dependencies.items():
            print("Checking", dep_name)
            dep_url = dep.url
            if dep_url is not None:
                print("Fetching", dep_name, "from", dep_url)

                cmd = [zig, "fetch", "--global-cache-dir", file.join_path([fs.homedir(), ".cache", "acton", "build-cache"]), dep_url]
                p = process.RunProcess(
                    pcap,
                    cmd,
                    lambda p, exit_code, term_signal, stdout_buf, stderr_buf: on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf),
                    lambda p, error: on_error(dep, p, error))
                dep_processes[dep.name] = p

        for dep_name, dep in build_config.zig_dependencies.items():
            print("Checking", dep_name)
            dep_url = dep.url
            if dep_url is not None:
                print("Fetching", dep_name, "from", dep_url)

                cmd = [zig, "fetch", "--global-cache-dir", file.join_path([fs.homedir(), ".cache", "acton", "build-cache"]), dep_url]
                p = process.RunProcess(
                    pcap,
                    cmd,
                    lambda p, exit_code, term_signal, stdout_buf, stderr_buf: on_exit(dep, p, exit_code, term_signal, stdout_buf, stderr_buf),
                    lambda p, error: on_error(dep, p, error))
                zig_processes[dep.name] = p


actor CmdPkgAdd(env, args):
    """Add a package dependency to the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    # What arguments do we need?
    # - the name of the dependency (e.g. "foo", used in the build.act.json config file)
    # - the URL to fetch it from

    # We need to fetch the dependency and get the (content) hash of the fetched
    # dependency and store it in the build.act.json file. If the dependency is
    # already in the build.act.json file, we need to check if the hash is the
    # same as the one we just fetched. If it is, we do nothing. If it is not,

    dep_name = args.get_str("name")
    dep_url = args.get_str("url")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except:
            pass
        return BuildConfig()

    build_config = get_build_config()

    def on_exit(p, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            dep_hash = stdout_buf.decode().strip()

            if dep_name in build_config.dependencies:
                if build_config.dependencies[dep_name].hash == dep_hash:
                    print("Dependency", dep_name, "is already up to date")
                else:
                    print("Updated existing dependency", dep_name, "with new hash", dep_hash, " (old", build_config.dependencies[dep_name].hash, ")")
                    build_config.dependencies[dep_name].hash = dep_hash
            else:
                # Add the hash
                build_config.dependencies[dep_name] = Dependency(dep_name, dep_url, dep_hash)
                print("Added new package dependency", dep_name, "with hash", dep_hash)

            baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
            baj_file.write(build_config.to_json().encode()+b"\n")
            await async baj_file.close()

            env.exit(0)
        else:
            print("Error fetching", stderr_buf.decode())
            env.exit(1)

    def on_error(p, error):
        print("Error fetching", error)
        env.exit(1)

    cmd = [zig, "fetch", "--global-cache-dir", file.join_path([fs.homedir(), ".cache", "acton", "build-cache"]), args.get_str("url")]
    process.RunProcess(
        pcap,
        cmd,
        on_exit,
        on_error)


actor CmdPkgRemove(env, args):
    """Remove a package dependency from the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    dep_name = args.get_str("name")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except:
            print("No build.act.json file found, nothing to do.")
            await async env.exit(0)
        return BuildConfig() # unreachable

    build_config = get_build_config()

    if dep_name in build_config.dependencies:
        print("Removed package dependency", dep_name)
        del build_config.dependencies[dep_name]
    else:
        print("Dependency", dep_name, "not found in build.act.json. Nothing to do.")

    baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
    baj_file.write(build_config.to_json().encode()+b"\n")
    await async baj_file.close()

    env.exit(0)


actor CmdZigPkgAdd(env, args):
    """Add a zig package dependency to the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    # What arguments do we need?
    # - the name of the dependency (e.g. "foo", used in the build.act.json config file)
    # - the URL to fetch it from

    # We need to fetch the dependency and get the (content) hash of the fetched
    # dependency and store it in the build.act.json file. If the dependency is
    # already in the build.act.json file, we need to check if the hash is the
    # same as the one we just fetched. If it is, we do nothing. If it is not,

    dep_name = args.get_str("name")
    dep_url = args.get_str("url")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except:
            pass
        return BuildConfig()

    build_config = get_build_config()

    def on_exit(p, exit_code, term_signal, stdout_buf, stderr_buf):
        if exit_code == 0:
            dep_hash = stdout_buf.decode().strip()

            if dep_name in build_config.zig_dependencies:
                if build_config.zig_dependencies[dep_name].hash == dep_hash:
                    print("Dependency", dep_name, "is already up to date")
                else:
                    print("Updated existing dependency", dep_name, "with new hash", dep_hash, " (old", build_config.zig_dependencies[dep_name].hash, ")")
                    build_config.zig_dependencies[dep_name].hash = dep_hash
            else:
                # Add the hash
                build_config.zig_dependencies[dep_name] = Dependency(dep_name, dep_url, dep_hash)
                print("Added new Zig package dependency", dep_name, "with hash", dep_hash)

            baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
            baj_file.write(build_config.to_json().encode()+b"\n")
            await async baj_file.close()

            env.exit(0)
        else:
            print("Error fetching", stderr_buf.decode())
            env.exit(1)

    def on_error(p, error):
        print("Error fetching", error)
        env.exit(1)

    cmd = [zig, "fetch", "--global-cache-dir", file.join_path([fs.homedir(), ".cache", "acton", "build-cache"]), args.get_str("url")]
    process.RunProcess(
        pcap,
        cmd,
        on_exit,
        on_error)


actor CmdZigPkgRemove(env, args):
    """Remove a package dependency from the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    dep_name = args.get_str("name")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except:
            print("No build.act.json file found, nothing to do.")
            await async env.exit(0)
        return BuildConfig() # unreachable

    build_config = get_build_config()

    if dep_name in build_config.zig_dependencies:
        print("Removed Zig package dependency", dep_name)
        del build_config.zig_dependencies[dep_name]
    else:
        print("Zig dependency", dep_name, "not found in build.act.json. Nothing to do.")

    baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
    baj_file.write(build_config.to_json().encode()+b"\n")
    await async baj_file.close()

    env.exit(0)


actor main(env):
    process_cap = process.ProcessCap(env.cap)

    def _compilefile(_file, args):
        cmdargs = build_cmd_args(args)
        cr = CompilerRunner(process_cap, env, [_file] + cmdargs)

    def _cmd_build(args):
        def on_build_success(stdout_buf):
            env.exit(0)

        def on_build_failure(exit_code: int,  term_signal: int, stderr_buf: str):
            print("Error building project", stderr_buf)
            env.exit(1)

        BuildProject(process_cap, env, args, on_build_success, on_build_failure, build_tests=False)

    def _cmd_doc(args):
        env.exit(0)

    def _cmd_fetch(args):
        c = CmdFetch(env, args)

    def _cmd_pkg(args):
        env.exit(0)

    def _cmd_pkg_add(args):
        c = CmdPkgAdd(env, args)

    def _cmd_pkg_rm(args):
        c = CmdPkgRemove(env, args)

    def _cmd_new(args):
        cr = CompilerRunner(process_cap, env, ["new", args.get_str("projectdir")])
        env.exit(0)

    def _cmd_test(args):
        run_tests = RunTestTest(env, args, perf_mode=False)

    def _cmd_test_perf(args):
        run_tests = RunTestTest(env, args, perf_mode=True)

    def _cmd_list_test(args):
        run_tests = RunTestList(env, args)

    def _cmd_version(args):
        if args.get_bool("full"):
            CompilerRunner(process_cap, env, ["--version"])
        else:
            CompilerRunner(process_cap, env, ["--numeric-version"])

    def _cmd_zigpkg(args):
        env.exit(0)

    def _cmd_zigpkg_add(args):
        c = CmdZigPkgAdd(env, args)

    def _cmd_zigpkg_rm(args):
        c = CmdZigPkgRemove(env, args)

    def _parse_args():
        p = argparse.Parser()
        p.add_bool("always-build", "Always build")
        p.add_bool("parse", "Show parsing result")
        p.add_bool("kinds", "Show results after kind checking")
        p.add_bool("types", "Show inferred expression types")
        p.add_bool("sigs", "Show inferred type signatures")
        p.add_bool("norm", "Show results after syntactic normalization")
        p.add_bool("deact", "Show results after deactorization")
        p.add_bool("cps", "Show results after CPS conversion")
        p.add_bool("llift", "Show results of lambda lifting")
        p.add_bool("hgen", "Show generated .h header")
        p.add_bool("cgen", "Show generated .c code")
        p.add_bool("ccmd", "Show CC / LD command lines")
        p.add_bool("timing", "Show timing information")
        p.add_bool("auto-stub", "Allow automatica stub detection")
        p.add_bool("stub", "Stub (.ty) file generation only")
        p.add_bool("cpedantic", "Pedantic C compilation")
        p.add_bool("quiet", "Be quiet")
        p.add_bool("debug", "Print debug stuff")
        p.add_bool("dev", "Development mode")
        p.add_bool("only-build", "Only perform final build of .c files, do not compile .act files")
        p.add_bool("skip-build", "Skip final build of .c files")
        p.add_bool("keepbuild", "Keep build.zig")
        p.add_option("root", "str", "?", "", "Set root actor")
        p.add_option("tempdir", "str", "?", "", "Directory for temporary build files")
        p.add_option("syspath", "str", "?", "", "syspath")
        p.add_option("target", "str", "?", "", "Target, e.g. x86_64-linux-gnu.2.28")
        p.add_arg("file", ".act file to compile, or .ty to show", False, "?")

        p_build = p.add_cmd("build", "Build", _cmd_build)

        p_fetch = p.add_cmd("fetch", "Fetch all the things for offline work", _cmd_fetch)

        p_pkg = p.add_cmd("pkg", "Manage package dependencies", _cmd_pkg)

        p_pkg_add = p_pkg.add_cmd("add", "Add package dependency", _cmd_pkg_add)
        p_pkg_add.add_arg("url", "URL of dependency", True, "?")
        p_pkg_add.add_arg("name", "Name of dependency", True, "?")
        p_pkg_add.add_option("hash", "str", "?", "", "Hash of dependency")

        p_pkg_rm = p_pkg.add_cmd("remove", "Remove package dependency", _cmd_pkg_rm)
        p_pkg_rm.add_arg("name", "Name of dependency", True, "?")

        docp = p.add_cmd("doc", "Show documentation", _cmd_doc)

        newp = p.add_cmd("new", "New project", _cmd_new)
        newp.add_arg("projectdir", "Project directory", True, "?")

        testp = p.add_cmd("test", "Test", _cmd_test)
        testp.add_bool("record", "Record test performance results")
        testp.add_option("module", "strlist", "+", [], "Filter on test module name")
        testp.add_option("name", "strlist", "+", [], "Filter on test name")

        testlistp = testp.add_cmd("list", "List tests", _cmd_list_test)

        testperfp = testp.add_cmd("perf", "Perf", _cmd_test_perf)

        version_p = p.add_cmd("version", "Show version", _cmd_version)
        version_p.add_bool("full", "Show full version info")

        p_zigpkg = p.add_cmd("zig-pkg", "Manage Zig package dependencies", _cmd_zigpkg)

        p_zigpkg_add = p_pkg.add_cmd("add", "Add Zig package dependency", _cmd_zigpkg_add)
        p_zigpkg_add.add_arg("url", "URL of dependency", True, "?")
        p_zigpkg_add.add_arg("name", "Name of dependency", True, "?")
        p_zigpkg_add.add_option("hash", "str", "?", "", "Hash of dependency")

        p_zigpkg_rm = p_pkg.add_cmd("remove", "Remove Zig package dependency", _cmd_zigpkg_rm)
        p_zigpkg_rm.add_arg("name", "Name of dependency", True, "?")

        return p.parse(env.argv)

    try:
        _args = _parse_args()
        _cmd = _args.cmd
        _file = None
        try:
            _file = _args.get_str("file")
        except argparse.ArgumentError:
            pass
        if _cmd is not None:
            if _file is not None and (_file.endswith(".act") or _file.endswith(".ty")):
                print("Error: cannot specify both a command and an .act/.ty file", err=True)
                await async env.exit(1)
            _cmd(_args)
        else:
            if _file is not None:
                _compilefile(_file, _args)
            else:
                env.exit(0)
    except argparse.PrintUsage as exc:
        print(exc.error_message)
        env.exit(0)
    except argparse.ArgumentError as exc:
        print(exc.error_message)
        env.exit(1)
