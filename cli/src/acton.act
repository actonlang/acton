import argparse
import file
import json
import process
import term
import testing

from buildy import *
from testing import TestInfo

def get_zig_local_cache_dir(file_cap: file.FileCap):
    fs = file.FS(file_cap)
    return file.join_path([fs.homedir(), ".cache", "acton", "zig-local-cache"])

def get_zig_global_cache_dir(file_cap: file.FileCap):
    fs = file.FS(file_cap)
    return file.join_path([fs.homedir(), ".cache", "acton", "zig-global-cache"])

def base_path(file_cap: file.FileCap):
    fs = file.FS(file_cap)
    return fs.exepath()[0:-len("/bin/acton")]

def warn_on_large_zig_global_cache(cap: file.FileCap):
    fs = file.FS(cap)
    last_warn_file = file.join_path([get_zig_global_cache_dir(cap), "last_warn"])
    warn_level: int = 10 # start to warn at 10GB
    try:
        last_warn = int(file.ReadFile(file.ReadFileCap(cap), last_warn_file).read().decode())
        warn_level = last_warn + 1 # warn in 1GB increments
    except:
        try:
            f = file.WriteFile(file.WriteFileCap(cap), last_warn_file)
            f.write(str(warn_level).encode())
            f.close()
        except:
            # The cache dir probably doesn't exist, just ignore
            pass

    cache_dir = get_zig_global_cache_dir(cap)
    total_size: int = 0
    for f in fs.walk(cache_dir):
        total_size += int(f.size)
    gb = 1024 * 1024 * 1024
    if total_size > warn_level * gb:
        print("WARN: The global cache has grown to %dMB" % (total_size // (1024*1024)))
        print("HINT: You can clear the cache with with: rm -rf %s" % cache_dir)
        print("INFO: Do NOT clear the cache if you are offline or have a slow connection.")
        print("INFO: The global cache stores downloaded package dependencies as well as")
        print("INFO: compiled artifacts for common libraries, like libc.")
        print("INFO: Another warning will be issued when the cache grows by another 1GB.")
        print("")
        # write new warn level
        try:
            f = file.WriteFile(file.WriteFileCap(cap), last_warn_file)
            f.write(str(total_size // gb).encode())
            f.close()
        except Exception as e:
            print("WARN: Could not write new warn level to", last_warn_file)
            print(e)
    if total_size == 0:
        print("INFO: Acton global cache is empty: rebuilding common libraries (e.g. libc) which will take some time...")

def clean_zig_local_cache(cap: file.FileCap):
    fs = file.FS(cap)
    cache_dir = get_zig_local_cache_dir(cap)
    total_size = 0
    for f in fs.walk(cache_dir):
        total_size += f.size
    gb = 1024 * 1024 * 1024
    limit = 5 * gb
    if total_size > limit:
        print("Build cache (", total_size // (1024*1024), "MB) over %dGB, cleaning it up." % (int(limit // gb)))
        fs.rmtree(cache_dir)
        total_size = 0
    if total_size == 0:
        print("INFO: Acton local cache is empty: rebuilding Acton base which will take some time...")

def write_buildzig(file_cap, build_config: BuildConfig):
    fs = file.FS(file_cap)

    def get_build_zig_templates():
        # Read the build.zig template
        build_zig_template = file.ReadFile(
            file.ReadFileCap(file_cap),
            file.join_path([base_path(file_cap), "builder", "build.zig"])).read().decode()
        build_zig_zon_template = file.ReadFile(
            file.ReadFileCap(file_cap),
            file.join_path([base_path(file_cap), "builder", "build.zig.zon"])).read().decode()
        return build_zig_template, build_zig_zon_template

    build_zig_tpl, build_zig_zon_tpl = get_build_zig_templates()
    # Write build.zig
    b_file = file.WriteFile(file.WriteFileCap(file_cap), "build.zig")
    await async b_file.write(gen_buildzig(build_zig_tpl, build_config).encode())
    await async b_file.close()
    # Write build.zig.zon
    bzz_file = file.WriteFile(file.WriteFileCap(file_cap), "build.zig.zon")
    await async bzz_file.write(gen_buildzigzon(build_zig_zon_tpl, build_config).encode())
    await async bzz_file.close()


actor CompilerRunner(process_cap, env, args, wdir=None, on_exit: ?action(int, int, bytes, bytes) -> None=None, on_error: ?action(str) -> None=None, print_output: bool=True, exe="actonc"):
    """Run the actonc compiler

    Will run actonc with the provided command and arguments. It is possible to
    inject callbacks when actonc exits or encounters an error. If no callbacks
    are provided, the default behavior is to exit when actonc does, possibly
    with an error message. Similarly, if actonc encounters an error, it will
    print the error message and exit.
    """
    var std_out_buf = b""
    var std_err_buf = b""

    def on_actonc_std_err(p, data):
        std_err_buf += data
        if print_output:
            print(data.decode(), end="")

    def on_actonc_std_out(p, data):
        std_out_buf += data
        if print_output:
            print(data.decode(), end="")

    def on_actonc_exit(p, exit_code, term_signal):
        if on_exit is not None:
            on_exit(exit_code, term_signal, std_out_buf, std_err_buf)
        else:
            if exit_code != 0:
                print("actonc exited with code: ", exit_code, " terminated with signal:", term_signal)
            env.exit(exit_code)

    def on_actonc_error(p, error: str):
        if on_error is not None:
            on_error(error)
        else:
            print("Error from process:", error)
            env.exit(1)


    fs = file.FS(file.FileCap(env.cap))
    # We find the path to actonc by looking at the executable path of the
    # current process. Since we are called 'acton', we just add a 'c'.
    cmd = [fs.exepath() + ("c" if exe == "actonc" else "")] + args
    p = process.Process(process_cap, cmd, on_actonc_std_out, on_actonc_std_err, on_actonc_exit, on_actonc_error, wdir)

    def stop():
        p.stop()

actor BuildProject(process_cap, env, args, on_build_success: action(str) -> None, on_build_failure: action(int, int, str) -> None, build_tests: bool=False, files: list[str]=[]):
    """Build the project including dependencies

    - check for dependencies.json, if found, download dependencies
    - build dependencies
    - build
    """
    fcap = file.FileCap(env.cap)
    rfcap = file.ReadFileCap(fcap)
    fs = file.FS(fcap)
    lock_file = None
    remaining_deps = {}
    zig_global_cache_dir = get_zig_global_cache_dir(file.FileCap(env.cap))
    if len(files) > 1:
        raise NotImplementedError("Multiple files not supported yet")

    dep_path_overrides = {}
    for dep_arg in args.get_strlist("dep"):
        parts = dep_arg.split("=", 1)
        dep_name, dep_path = parts[0], parts[1]
        # Ensure we have absolute paths
        abs_path = file.resolve_relative_path(fs.cwd(), dep_path)
        dep_path_overrides[dep_name] = abs_path

    var build_config = BuildConfig()

    def _on_actonc_exit(exit_code, term_signal, std_out_buf, std_err_buf):
        if exit_code == 0:
            on_build_success(std_out_buf.decode())
        else:
            on_build_failure(exit_code, term_signal, std_out_buf.decode() + std_err_buf.decode())

    def _on_actonc_failure(error: str):
        on_build_failure(-999, -999, error)

    def build_project():
        search_paths = []
        for dep_name, dep in build_config.dependencies.items():
            dep_hash = dep.hash
            dep_path = dep.path
            if dep_path is not None:
                # TODO: deconstruct and put together to get OS independent path? i.e. flip / to \ on windows
                if len(dep_path) == 0:
                    pass
                elif dep_path[0] == "/":
                    search_paths.append(file.join_path([dep_path, "out", "types"]))
                else:
                    search_paths.append(file.join_path([fs.cwd(), dep_path, "out", "types"]))
            elif dep_hash is not None:
                # For dependencies with hashes, we have previously copied them
                # from the Zig global cache to .build/deps/
                dep_dirname = dep_name + "-" + dep_hash
                search_paths.append(file.join_path([fs.cwd(), ".build", "deps", dep_dirname, "out", "types"]))
            else:
                raise ValueError("Dependency %s has no path or hash" % dep_name)
        search_path_arg = []
        for sp in search_paths:
            search_path_arg.extend(["--searchpath", sp])
        cmdargs = []
        if files == []:
            cmdargs.extend(["build"])
        else:
            cmdargs.extend([files[0]])
        cmdargs.extend(build_cmd_args(args))
        if build_tests:
            cmdargs.append("--dev")
            cmdargs.append("--test")
        cmd = cmdargs + search_path_arg
        cr = CompilerRunner(
            process_cap,
            env,
            cmd,
            None,
            _on_actonc_exit,
            _on_actonc_failure,
            print_output=not build_tests
        )

    def _on_dep_actonc_exit(dep_name, exit_code, term_signal, std_out_buf, std_err_buf):
        if exit_code == 0:
            print("Dependency", dep_name, "built successfully")
            try:
                del remaining_deps[dep_name]
            except KeyError:
                pass

            if len(remaining_deps) == 0:
                print("All dependencies built, building main project")
                build_project()
        else:
            print("ERROR: Error building dependency", dep_name)
            for dep in remaining_deps.values():
                dep.stop()
            env.exit(1)


    def on_dep_build_error(name, error):
        print("Error building dependency", name, error)
        env.exit(1)

    def build_deps():
        # Find dependencies and compile them first
        if len(build_config.dependencies) == 0:
            build_project()
        else:
            print("Building dependencies:")
            for dep_name, dep in build_config.dependencies.items():
                dep_hash = dep.hash
                dep_path = dep.path
                path = ""
                if dep_path is not None:
                    path = dep_path
                elif dep_hash is not None:
                    path = file.join_path([".build", "deps", dep_name + "-" + dep_hash])
                else:
                    raise ValueError("Dependency %s has no path or hash" % dep_name)
                print(" -", dep_name)
                dep_args = []
                for dep_arg in args.get_strlist("dep"):
                    dep_args.extend(["--dep", dep_arg])
                cmd = ["build"] + build_cmd_args(args) + ["--keepbuild"] + dep_args
                cr = CompilerRunner(
                    process_cap,
                    env,
                    cmd,
                    path,
                    lambda exit_code, term_signal, std_out_buf, std_err_buf: _on_dep_actonc_exit(dep_name, exit_code, term_signal, std_out_buf, std_err_buf),
                    lambda error_msg: on_dep_build_error(dep_name, error_msg),
                    exe="acton"
                )
                remaining_deps[dep_name] = cr

    def check_deps():
        # 1. fetch dependencies (into zig global cache)
        # 2. copy dependencies from zig global cache to deps/
        # 3. build dependencies
        # 4. build project
        deps_dir = set()
        try:
            await async fs.mkdir(".build")
        except:
            pass

        try:
            await async fs.mkdir(file.join_path([".build", "deps"]))
        except:
            pass

        try:
            deps_dir = set(fs.listdir(file.join_path([".build", "deps"])))
        except OSError:
            pass

        for dep_name, dep in build_config.dependencies.items():
            # Does deps/X exist?
            dep_hash = dep.hash
            dep_path = dep.path
            if dep_path is not None:
                pass
            elif dep_hash is not None:
                dep_dirname = dep_name + "-" + dep_hash
                if dep_dirname not in deps_dir:
                    src = file.join_path([zig_global_cache_dir, "p", dep_hash])
                    dst = file.join_path([fs.cwd(), ".build", "deps", dep_dirname])
                    try:
                        await async fs.mkdir(dst)
                    except:
                        pass
                    print("Copying %s dependency from zig global cache to project local build deps, hash: %s" % (dep_name, dep_hash))
                    await async fs.copytree(src, dst)
            else:
                raise ValueError("Dependency %s has no hash or path set" % dep_name)
        build_deps()

    def on_zig_fetch_error(errmsg):
        print(errmsg, err=True)
        env.exit(1)

    def check_for_buildconfig():
        """Check if dependencies.json exists

        If there is a dependencies.json file, we will read it and check if the
        dependencies also exist locally. If not, we will download them and
        proceed to build the dependencies and then build the project.

        If there is no dependencies.json file, we will build the project.
        """
        try:
            build_config = BuildConfig.from_json(file.ReadFile(rfcap, "build.act.json").read().decode())
        except FileNotFoundError:
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            env.exit(1)
            return

        build_config_fetchable = BuildConfig()
        for dep_name, dep in build_config.dependencies.items():
            if dep_name in dep_path_overrides:
                dep_path = dep_path_overrides[dep_name]
                # Zig wants relative paths
                rel_path = file.get_relative_path(dep_path, fs.cwd())
                dep.path = rel_path
                print("INFO: Using dependency path %s for %s" % (rel_path, dep.name), err=True)
            else:
                build_config_fetchable.dependencies[dep_name] = dep

        for dep_name, dep in build_config.zig_dependencies.items():
            build_config_fetchable.zig_dependencies[dep_name] = dep

        write_buildzig(file.FileCap(env.cap), build_config)
        zfd = ZigFetchDeps(env, build_config_fetchable, lambda x, y: check_deps(), on_zig_fetch_error)

    def get_lock():
        """Try to get the build lock for the project
        """
        try:
            lock_file = file.WriteFile(file.WriteFileCap(fcap), ".acton.lock", lock=True)
            check_for_buildconfig()
        except OSError:
            print("Build lock exists, trying again soon...")
            after 1: get_lock()

    # check cache size and warn or clean if necessary...
    warn_on_large_zig_global_cache(file.FileCap(env.cap))
    clean_zig_local_cache(file.FileCap(env.cap))
    # and off we go! Start by grabbing the project build lock
    get_lock()


actor RunModuleTest(process_cap, modname, test_cmd, on_json_output, on_test_error):
    var captured_std_out = b""
    var std_err_buf = b""
    var captured_std_err = b""

    def on_std_out(p, data: bytes):
        captured_std_out += data

    def on_std_err(p, data):
        # TODO: we shouldn't sent test data in-band on std_err - should be separate pipe
        std_err_buf += data
        lines = std_err_buf.splitlines(True)
        std_err_buf = b""
        for i, line in enumerate(lines):
            if not line.endswith(b"\n"):
                std_err_buf = b"".join(lines[i:])
                break

            # We have a complete line, check if it is valid JSON
            try:
                upd = json.decode(line.decode())
                # We have a complete JSON object, pass it to the callback
                on_json_output(self, upd, captured_std_out, captured_std_err)
            except ValueError:
                # Not a complete JSON object, append to captured_std_err
                if line != b"\n":
                    captured_std_err += line

    def on_exit(p, exit_code, term_signal):
        if exit_code != 0 or term_signal != 0:
            on_test_error(exit_code, term_signal, captured_std_out.decode() + captured_std_err.decode())

    def on_error(p, error):
        on_test_error(-1, -1, error)

    # TODO: fs.join()
    cmd = ["out/bin/.test_" + modname, "--json"] + test_cmd
    p = process.Process(process_cap, cmd, on_std_out, on_std_err, on_exit, on_error)

    def stop():
        p.stop()


actor CmdListTest(env, args):
    """Print list of module tests

    Will run the project module test binaries with 'list --json' to get all
    module tests, collect the output and print a list of all project tests.
    """
    process_cap = process.ProcessCap(env.cap)

    def print_module_tests(err, tests: dict[str, dict[str, testing.TestInfo]]={}):
        if err != None:
            print(err, err=True)
            env.exit(1)
            return

        for module_name, module_tests in tests.items():
            print("Module %s:" % module_name)
            for test_name in module_tests:
                print(" ", test_name)
            print()
        env.exit(0)

    def _on_build_success(std_out_buf: str):
        test_modules = []
        std_out_tests = False
        for line in std_out_buf.splitlines(False):
            if line.startswith("Test executables:"):
                std_out_tests = True
            else:
                if std_out_tests:
                    test_modules.append(line)
        l = ListTests(process_cap, test_modules, print_module_tests)

    def _on_build_failure(exit_code, term_signal, std_err_buf: str):
        print("Failed to build project tests")
        print("actonc exited with code %d / %d" % (exit_code, term_signal))
        print("std_err:", std_err_buf)
        env.exit(1)

    project_builder = BuildProject(
        process_cap,
        env,
        args,
        _on_build_success,
        _on_build_failure,
        build_tests=True
    )


actor ListTests(process_cap, test_modules: list[str], on_done: action(?str, ?dict[str, dict[str, testing.TestInfo]]) -> None):
    """List all tests in project
    """
    remaining_mods = {}
    tests: dict[str, dict[str, testing.TestInfo]] = {}

    def _on_exit(module_name, p, exit_code, term_signal, std_out_buf, std_err_buf):
        if exit_code == 0:
            tests[module_name] = {}
            try:
                data = json.decode(std_err_buf.decode())
                if isinstance(data, dict):
                    if "tests" in data:
                        for test_name, json_test_info in data["tests"].items():
                            if isinstance(json_test_info, dict):
                                tests[module_name][test_name] = TestInfo.from_json(json_test_info)
                        del remaining_mods[module_name]
                        if len(remaining_mods) == 0:
                            on_done(None, tests)
                    else:
                        on_done("Error listing tests for module %s: no 'tests' key in JSON" % module_name)
            except ValueError as e:
                on_done("Error parsing JSON from module %s: %s" % (module_name, str(e)))
        else:
            on_done("Error listing tests for module %s, exited with code %d and term signal %d: %s" % (module_name, exit_code, term_signal, std_err_buf.decode()))

    def _on_error(module_name, p, error):
        err = "ERROR: Error listing tests for module %s: %s" % (module_name, error)
        for op in remaining_mods.values():
            op.stop()
        on_done(err)

    if len(test_modules) == 0:
        on_done(None, {})

    # List all tests by asking each module about its tests. This runs in
    # parallel.
    for module_name in test_modules:
        cmd = [file.join_path(["out", "bin", ".test_" + module_name]), "list", "--json"]
        p = process.RunProcess(
            process_cap,
            cmd,
            lambda p, exit_code, term_signal, std_out_buf, std_err_buf: _on_exit(module_name, p, exit_code, term_signal, std_out_buf, std_err_buf),
            lambda p, error: _on_error(module_name, p, error))
        remaining_mods[module_name] = p


actor CmdTest(env: Env, args, perf_mode: bool=False):
    """Run project tests, i.e. `acton test`
    """
    process_cap = process.ProcessCap(env.cap)
    # TODO: test concurrency should consider the type of test, so unit tests get
    # 1 CPU while actor / env tests get more. This is a simple approximation for
    # a start...
    concurrency = env.nr_wthreads // 2
    var running_tests = {}
    var tests_to_run = []
    var perf_data = "{}"
    fs = file.FS(file.FileCap(env.cap))

    test_cmd_args = []
    for name_filter in args.get_strlist("name"):
        test_cmd_args.extend(["--name", name_filter])

    try:
        perf_file = file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "perf_data")
        perf_data = perf_file.read().decode()
    except:
        pass
    ptr = testing.ProjectTestResults(perf_data, perf_mode)

    def _periodic_show():
        r = ptr.show(only_show_complete=not env.is_tty())
        if r is not None:
            if args.get_bool("record"):
                perf_wfile = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "perf_data")
                perf_wfile.write(ptr.to_json().encode())
                perf_wfile.close()
            if args.get_bool("golden-update"):
                for module_name, tests in ptr.results.items():
                    for test_name, test_info in tests.items():
                        exc = test_info.exception
                        output = test_info.output
                        if exc is not None and output is not None and exc.startswith("testing.NotEqualError: Test output does not match expected golden value"):
                            rpath = ["test", "golden", module_name]
                            filename = file.join_path([fs.cwd()] + rpath + [test_name])
                            for idx in range(1, len(rpath)+1):
                                mkdir_path = file.join_path([fs.cwd()] + rpath[0:idx])
                                try:
                                    a = fs.mkdir(mkdir_path)
                                except:
                                    pass
                            golden_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), filename)
                            golden_file.write(output.encode())
                            await async golden_file.close()

            env.exit(r)
            return
        after 0.05: _periodic_show()

    def _on_json_output(rmt, test, data, std_out_buf, std_err_buf):
        if isinstance(data, dict):
            if "test_info" in data:
                test_info = TestInfo.from_json(data["test_info"])
                test_info.std_out = std_out_buf.decode()
                test_info.std_err = std_err_buf.decode()
                ptr.update(test_info.definition.module, test_info.definition.name, test_info)
                if test_info.complete:
                    if test_info.success == None and test_info.exception == "Test timeout":
                        rmt.stop()
                    _run_test()
        else:
            raise ValueError("Unexpected JSON data from module test: " + test.module)

    def _on_test_error(test: testing.Test, exit_code: int, term_signal: int, errout: str):
        errmsg = "Test error, exit_code %d and term signal %d, errout: " % (exit_code, term_signal)
        errmsg += errout
        # We construct our own TestInfo here since we didn't get one from the
        # test process, because it crashed...
        ptr.update(
            test.module,
            test.name,
            testing.TestInfo(
                test,
                complete=True,
                success=None,
                exception="Test crash, exit_code %d and term signal %d" % (exit_code, term_signal),
                num_iterations=1,
                num_failures=0,
                num_errors=1
            ))
        _run_test()

    def _run_test():
        try:
            test_info = tests_to_run.pop(0)
            cmd = ["test", test_info.definition.name]
            if perf_mode:
                cmd += ["perf"]
            cmd += test_cmd_args
            t = RunModuleTest(
                process_cap,
                test_info.definition.module,
                cmd,
                lambda rmt, x, std_out_buf, std_err_buf: _on_json_output(rmt, test_info.definition, x, std_out_buf, std_err_buf),
                lambda x, y, z: _on_test_error(test_info.definition, x, y, z))
            running_tests[test_info.definition] = t
            if len(running_tests) < concurrency:
                _run_test()
        except IndexError:
            pass
        _periodic_show()

    def _list_tests(built_modules: list[str]):
        list_modules = []
        select_modules = set(args.get_strlist("module"))
        if len(select_modules) > 0:
            for module_name in built_modules:
                if module_name in select_modules:
                    list_modules.append(module_name)
        else:
            list_modules = built_modules

        if len(list_modules) == 0:
            print("No tests found")
            env.exit(0)
            return

        ListTests(process_cap, list_modules, _on_list_output)

    def _on_list_output(err, tests: dict[str, dict[str, testing.TestInfo]]={}):
        if err != None:
            print(err, err=True)
            env.exit(1)
            return


        expected_modules = set()
        name_filter = set(args.get_strlist("name"))
        for module_name in sorted(tests.keys()):
            module_tests = tests[module_name]
            if len(module_tests) > 0:
                expected_modules.add(module_name)
            for test_name, test_info in module_tests.items():
                if len(name_filter) == 0 or test_name in name_filter:
                    ptr.update(module_name, test_name, test_info)
                    tests_to_run.append(test_info)
        ptr.expected_modules = expected_modules

        _run_test()

    def _on_build_success(std_out_buf: str):
        print(term.clearline + term.up() + term.clearline, end="")
        test_modules = []
        std_out_tests = False
        for line in std_out_buf.splitlines(False):
            if line.startswith("Test executables:"):
                std_out_tests = True
            else:
                if std_out_tests:
                    test_modules.append(line)
        _list_tests(test_modules)

    def _on_build_failure(exit_code, term_signal, std_err_buf: str):
        print("Failed to build project tests")
        print("actonc exited with code %d / %d" % (exit_code, term_signal))
        print("std_err:", std_err_buf)
        env.exit(1)

    # TODO: let dev mode enable for normal test and disable, i.e. use release mode for perf tests
    # However, we have some stability issue due to wonky compilation
    # optimizations so we get crashes. Thus we now always run in dev mode to get
    # actually working code.
    #dev = not perf_mode
    dev = True
    print("Building project tests...")
    project_builder = BuildProject(process_cap, env, args, _on_build_success, _on_build_failure, build_tests=True)


def build_cmd_args(args):
    cmdargs = []
    for argname, arg in args.options.items():
        # TODO: reverse this logic, we should only pass in a small set of options, not all
        if argname in {"file", "record", "golden-update"}:
            continue
        if arg.type == "bool":
            if args.get_bool(argname):
                cmdargs.append("--" + argname)
        elif arg.type == "str":
            if args.get_str(argname) != '':
                cmdargs.append("--" + argname)
                cmdargs.append(args.get_str(argname))
        elif arg.type == "int":
            if args.get_int(argname) != 0:
                cmdargs.append("--" + argname)
                cmdargs.append(str(args.get_int(argname)))

    return cmdargs


actor ZigFetchDeps(env, build_config: BuildConfig, on_done: action(int, int) -> None, on_fetch_error: action(str) -> None, print_output: bool=False):
    """Fetch dependencies and Zig dependencies
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))
    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    remaining_deps = {}

    dep_processes = {}
    zig_processes = {}
    var total = 0
    var fetched = 0

    def _on_exit(dep: Dependency, p, exit_code, term_signal, std_out_buf, std_err_buf):
        if exit_code == 0:
            fetched_hash: str = std_out_buf.decode().strip()
            if print_output:
                print("Fetched dependency %s with hash %s" % (dep.name, fetched_hash), err=True)

            dep_hash = dep.hash
            if dep_hash is not None:
                if dep_hash != fetched_hash:
                    errmsg = "ERROR: hash mismatch for dependency %s" % dep.name
                    errmsg += "\nDETAIL: fetched hash (%s) differs from configured hash (%s)" % (fetched_hash, dep_hash)
                    errmsg += "\nHINT: Update build.act.json with the correct hash. Prefer immutable URLs, like a ref to an immutable git tag over a mutable git branch."
                    on_fetch_error(errmsg)
                    return

            fetched += 1
            if isinstance(dep, PkgDependency):
                del dep_processes[dep.name]
            elif isinstance(dep, ZigDependency):
                del zig_processes[dep.name]

            if len(dep_processes) == 0 and len(zig_processes) == 0:
                on_done(total, fetched)
        else:
            on_fetch_error(std_err_buf.decode())

    def _on_error(dep, p, error):
        # TODO: collect all errors before calling on_fetch_error?
        on_fetch_error(error)

    zig_global_cache_dir = get_zig_global_cache_dir(file.FileCap(env.cap))
    for dep_name, dep in build_config.dependencies.items():
        total += 1
        dep_path = dep.path
        if dep_path is not None:
            if print_output:
                print("Skip fetching dependency %s that uses local path (%s)" % (dep.name, dep_path))
            continue

        dep_url = dep.url
        dep_hash = dep.hash
        if dep_url is not None:
            if dep_hash is not None:
                dep_dir = file.join_path([zig_global_cache_dir, "p", dep_hash])
                try:
                    s = fs.stat(dep_dir)
                    continue
                except:
                    pass
            else:
                on_fetch_error("dependency %s does not have a hash configured")

            cmd = [zig, "fetch", "--global-cache-dir", zig_global_cache_dir, dep_url]
            p = process.RunProcess(
                pcap,
                cmd,
                lambda p, exit_code, term_signal, std_out_buf, std_err_buf: _on_exit(dep, p, exit_code, term_signal, std_out_buf, std_err_buf),
                lambda p, error: _on_error(dep, p, error))
            dep_processes[dep.name] = p

    for dep_name, dep in build_config.zig_dependencies.items():
        total += 1
        dep_path = dep.path
        if dep_path is not None:
            if print_output:
                print("Skip fetching dependency %s that uses local path (%s)" % (dep.name, dep_path))
            continue

        dep_url = dep.url
        dep_hash = dep.hash
        if dep_url is not None:
            if dep_hash is not None:
                dep_dir = file.join_path([zig_global_cache_dir, "p", dep_hash])
                try:
                    s = fs.stat(dep_dir)
                    continue
                except:
                    pass
            else:
                on_fetch_error("dependency %s does not have a hash configured")

            cmd = [zig, "fetch", "--global-cache-dir", zig_global_cache_dir, dep_url]
            p = process.RunProcess(
                pcap,
                cmd,
                lambda p, exit_code, term_signal, std_out_buf, std_err_buf: _on_exit(dep, p, exit_code, term_signal, std_out_buf, std_err_buf),
                lambda p, error: _on_error(dep, p, error))
            zig_processes[dep.name] = p

    if len(dep_processes) == 0 and len(zig_processes) == 0:
        on_done(total, fetched)


actor CmdFetch(env, args):
    pcap = process.ProcessCap(env.cap)
    fcap = file.FileCap(env.cap)
    rfcap = file.ReadFileCap(fcap)
    fs = file.FS(file.FileCap(env.cap))
    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    remaining_deps = {}


    dep_processes = {}
    zig_processes = {}

    def all_done(total, fetched):
        if total == 0:
            print("No dependencies to fetch", err=True)
        else:
            print("All dependencies up to date", err=True)
        env.exit(0)

    def on_zig_fetch_error(errmsg):
        print(errmsg, err=True)
        env.exit(1)

    def _read_build_config():
        try:
            build_config = BuildConfig.from_json(file.ReadFile(rfcap, "build.act.json").read().decode())
            write_buildzig(file.FileCap(env.cap), build_config)
            zfd = ZigFetchDeps(env, build_config, all_done, on_zig_fetch_error, print_output=True)
        except FileNotFoundError:
            print("No build.act.json file found, nothing to do.")
            env.exit(0)
            return
        except ValueError as e:
            print("ERROR:", e.error_message)
            env.exit(1)
            return
    _read_build_config()


actor CmdPkgAdd(env, args):
    """Add a package dependency to the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    # What arguments do we need?
    # - the name of the dependency (e.g. "foo", used in the build.act.json config file)
    # - the URL to fetch it from

    # We need to fetch the dependency and get the (content) hash of the fetched
    # dependency and store it in the build.act.json file. If the dependency is
    # already in the build.act.json file, we need to check if the hash is the
    # same as the one we just fetched. If it is, we do nothing. If it is not,

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)
    dep_url = args.get_str("url")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except FileNotFoundError:
            # Ignore, we create a new file
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            await async env.exit(1)
        return BuildConfig()

    build_config = get_build_config()

    def on_exit(p, exit_code, term_signal, std_out_buf, std_err_buf):
        if exit_code == 0:
            dep_hash = std_out_buf.decode().strip()

            if dep_name in build_config.dependencies:
                bc_dep = build_config.dependencies[dep_name]
                if bc_dep.url != dep_url:
                    print("Updated existing dependency", dep_name, "with new URL", dep_url, " (old", bc_dep.url, ")")
                    bc_dep.url = dep_url
                if bc_dep.hash == dep_hash:
                    print("Dependency", dep_name, "is already up to date, hash:", dep_hash)
                else:
                    print("Updated existing dependency", dep_name, "with new hash", dep_hash, " (old", bc_dep.hash, ")")
                    bc_dep.hash = dep_hash
            else:
                # Add the hash
                build_config.dependencies[dep_name] = PkgDependency(dep_name, dep_url, dep_hash)
                print("Added new package dependency", dep_name, "with hash", dep_hash)

            baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
            baj_file.write(build_config.to_json().encode()+b"\n")
            await async baj_file.close()

            env.exit(0)
        else:
            print("Error fetching", std_err_buf.decode())
            env.exit(1)

    def on_error(p, error):
        print("Error fetching", error)
        env.exit(1)

    cmd = [zig, "fetch", "--global-cache-dir", get_zig_global_cache_dir(file.FileCap(env.cap)), args.get_str("url")]
    process.RunProcess(
        pcap,
        cmd,
        on_exit,
        on_error)


actor CmdPkgRemove(env, args):
    """Remove a package dependency from the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except FileNotFoundError:
            # Ignore, we create a new file
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            await async env.exit(1)
        return BuildConfig()

    build_config = get_build_config()

    if dep_name in build_config.dependencies:
        print("Removed package dependency", dep_name)
        del build_config.dependencies[dep_name]
    else:
        print("Dependency", dep_name, "not found in build.act.json. Nothing to do.")

    baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
    baj_file.write(build_config.to_json().encode()+b"\n")
    await async baj_file.close()

    env.exit(0)


actor CmdZigPkgAdd(env, args):
    """Add a zig package dependency to the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    # What arguments do we need?
    # - the name of the dependency (e.g. "foo", used in the build.act.json config file)
    # - the URL to fetch it from

    # We need to fetch the dependency and get the (content) hash of the fetched
    # dependency and store it in the build.act.json file. If the dependency is
    # already in the build.act.json file, we need to check if the hash is the
    # same as the one we just fetched. If it is, we do nothing. If it is not,

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)
    dep_url = args.get_str("url")
    dep_artifacts = args.get_strlist("artifact")

    def get_build_config():
        try:
            return BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
        except FileNotFoundError:
            # Ignore, we create a new file
            pass
        except ValueError as e:
            print("ERROR:", e.error_message)
            await async env.exit(1)
        return BuildConfig()

    build_config = get_build_config()

    def on_exit(p, exit_code, term_signal, std_out_buf, std_err_buf):
        if exit_code == 0:
            dep_hash = std_out_buf.decode().strip()

            if dep_name in build_config.zig_dependencies:
                if build_config.zig_dependencies[dep_name].url != dep_url:
                    print("Updated existing dependency", dep_name, "with new URL", dep_url, " (old", build_config.zig_dependencies[dep_name].url, ")")
                    build_config.zig_dependencies[dep_name].url = dep_url

                if build_config.zig_dependencies[dep_name].hash == dep_hash:
                    print("Dependency", dep_name, "is already up to date, hash:", dep_hash)
                else:
                    print("Updated existing dependency", dep_name, "with new hash", dep_hash, " (old", build_config.zig_dependencies[dep_name].hash, ")")
                    build_config.zig_dependencies[dep_name].hash = dep_hash
            else:
                # Add the hash
                build_config.zig_dependencies[dep_name] = ZigDependency(dep_name, dep_url, dep_hash, None, {}, dep_artifacts)
                print("Added new Zig package dependency", dep_name, "with hash", dep_hash)

            baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
            baj_file.write(build_config.to_json().encode()+b"\n")
            await async baj_file.close()

            env.exit(0)
        else:
            print("Error fetching", std_err_buf.decode())
            env.exit(1)

    def on_error(p, error):
        print("Error fetching", error)
        env.exit(1)

    cmd = [zig, "fetch", "--global-cache-dir", get_zig_global_cache_dir(file.FileCap(env.cap)), args.get_str("url")]
    process.RunProcess(
        pcap,
        cmd,
        on_exit,
        on_error)


actor CmdZigPkgRemove(env, args):
    """Remove a package dependency from the project
    """
    pcap = process.ProcessCap(env.cap)
    fs = file.FS(file.FileCap(env.cap))

    zig = file.join_path([base_path(file.FileCap(env.cap)), "zig", "zig"])

    dep_name = args.get_str("name")
    try:
        zig_safe_name(dep_name)
    except ValueError as e:
        print("ERROR:", e)
        env.exit(1)

    def _get_build_config():
        try:
            build_config = BuildConfig.from_json(file.ReadFile(file.ReadFileCap(file.FileCap(env.cap)), "build.act.json").read().decode())
            _remove_zig_pkg(build_config, dep_name)
        except FileNotFoundError:
            # Ignore, we create a new file
            print("No build.act.json file found, nothing to do.")
            env.exit(0)
        except ValueError as e:
            print("ERROR:", e.error_message)
            env.exit(1)

    def _remove_zig_pkg(build_config, dep_name):
        if dep_name in build_config.zig_dependencies:
            print("Removed Zig package dependency", dep_name)
            del build_config.zig_dependencies[dep_name]
        else:
            print("Zig dependency", dep_name, "not found in build.act.json. Nothing to do.")

        baj_file = file.WriteFile(file.WriteFileCap(file.FileCap(env.cap)), "build.act.json")
        baj_file.write(build_config.to_json().encode()+b"\n")
        await async baj_file.close()

        env.exit(0)

    _get_build_config()


actor main(env):
    file_cap = file.FileCap(env.cap)
    process_cap = process.ProcessCap(env.cap)

    def in_project(filename: str):
        """Are we in a project?
        """
        fs = file.FS(file_cap)
        try:
            s = fs.stat("Acton.toml")
        except:
            return False
        return True

    def _compilefile(_file, args):
        if in_project(_file):
            def on_build_success(std_out_buf):
                env.exit(0)

            def on_build_failure(exit_code: int,  term_signal: int, std_err_buf: str):
                print("Error building project", std_err_buf)
                env.exit(1)

            BuildProject(process_cap, env, args, on_build_success, on_build_failure, build_tests=False, files=[_file])
        else:
            cmdargs = build_cmd_args(args)
            cr = CompilerRunner(process_cap, env, [_file] + cmdargs)

    def _cmd_build(args):
        def on_build_success(std_out_buf):
            env.exit(0)

        def on_build_failure(exit_code: int,  term_signal: int, std_err_buf: str):
            print("Error building project", std_err_buf)
            env.exit(1)

        BuildProject(process_cap, env, args, on_build_success, on_build_failure, build_tests=False)

    def _cmd_doc(args):
        env.exit(0)

    def _cmd_fetch(args):
        c = CmdFetch(env, args)

    def _cmd_pkg(args):
        env.exit(0)

    def _cmd_pkg_add(args):
        c = CmdPkgAdd(env, args)

    def _cmd_pkg_rm(args):
        c = CmdPkgRemove(env, args)

    def _cmd_new(args):
        cr = CompilerRunner(process_cap, env, ["new", args.get_str("projectdir")])
        env.exit(0)

    def _cmd_test(args):
        run_tests = CmdTest(env, args, perf_mode=False)

    def _cmd_test_perf(args):
        run_tests = CmdTest(env, args, perf_mode=True)

    def _cmd_list_test(args):
        run_tests = CmdListTest(env, args)

    def _cmd_version(args):
        if args.get_bool("full"):
            CompilerRunner(process_cap, env, ["--version"])
        else:
            CompilerRunner(process_cap, env, ["--numeric-version"])

    def _cmd_zigpkg(args):
        env.exit(0)

    def _cmd_zigpkg_add(args):
        c = CmdZigPkgAdd(env, args)

    def _cmd_zigpkg_rm(args):
        c = CmdZigPkgRemove(env, args)

    def _parse_args():
        p = argparse.Parser()
        p.add_bool("always-build", "Always build")
        p.add_bool("parse", "Show parsing result")
        p.add_bool("kinds", "Show results after kind checking")
        p.add_bool("types", "Show inferred expression types")
        p.add_bool("sigs", "Show inferred type signatures")
        p.add_bool("norm", "Show results after syntactic normalization")
        p.add_bool("deact", "Show results after deactorization")
        p.add_bool("cps", "Show results after CPS conversion")
        p.add_bool("llift", "Show results of lambda lifting")
        p.add_bool("hgen", "Show generated .h header")
        p.add_bool("cgen", "Show generated .c code")
        p.add_bool("ccmd", "Show CC / LD command lines")
        p.add_bool("timing", "Show timing information")
        p.add_bool("auto-stub", "Allow automatica stub detection")
        p.add_bool("stub", "Stub (.ty) file generation only")
        p.add_bool("cpedantic", "Pedantic C compilation")
        p.add_bool("quiet", "Be quiet")
        p.add_bool("debug", "Print debug stuff")
        p.add_bool("dev", "Development mode")
        p.add_bool("only-build", "Only perform final build of .c files, do not compile .act files")
        p.add_bool("skip-build", "Skip final build of .c files")
        p.add_bool("keepbuild", "Keep build.zig")
        p.add_option("root", "str", "?", "", "Set root actor")
        p.add_option("tempdir", "str", "?", "", "Directory for temporary build files")
        p.add_option("syspath", "str", "?", "", "syspath")
        p.add_option("target", "str", "?", "", "Target, e.g. x86_64-linux-gnu.2.28")
        p.add_option("dep", "strlist", "+", [], "Override path to dependency, e.g. --dep-path foo=../my-foo-repo")
        p.add_arg("file", ".act file to compile, or .ty to show", False, "?")

        p_build = p.add_cmd("build", "Build", _cmd_build)

        p_fetch = p.add_cmd("fetch", "Fetch all the things for offline work", _cmd_fetch)

        p_pkg = p.add_cmd("pkg", "Manage package dependencies", _cmd_pkg)

        p_pkg_add = p_pkg.add_cmd("add", "Add package dependency", _cmd_pkg_add)
        p_pkg_add.add_arg("url", "URL of dependency", True, "?")
        p_pkg_add.add_arg("name", "Name of dependency", True, "?")
        p_pkg_add.add_option("hash", "str", "?", "", "Hash of dependency")

        p_pkg_rm = p_pkg.add_cmd("remove", "Remove package dependency", _cmd_pkg_rm)
        p_pkg_rm.add_arg("name", "Name of dependency", True, "?")

        docp = p.add_cmd("doc", "Show documentation", _cmd_doc)

        newp = p.add_cmd("new", "New project", _cmd_new)
        newp.add_arg("projectdir", "Project directory", True, "?")

        testp = p.add_cmd("test", "Test", _cmd_test)
        testp.add_bool("record", "Record test performance results")
        testp.add_bool("golden-update", "Update expected golden values based on current values")
        testp.add_option("module", "strlist", "+", [], "Filter on test module name")
        testp.add_option("name", "strlist", "+", [], "Filter on test name")

        testlistp = testp.add_cmd("list", "List tests", _cmd_list_test)

        testperfp = testp.add_cmd("perf", "Perf", _cmd_test_perf)

        version_p = p.add_cmd("version", "Show version", _cmd_version)
        version_p.add_bool("full", "Show full version info")

        p_zigpkg = p.add_cmd("zig-pkg", "Manage Zig package dependencies", _cmd_zigpkg)

        p_zigpkg_add = p_zigpkg.add_cmd("add", "Add Zig package dependency", _cmd_zigpkg_add)
        p_zigpkg_add.add_arg("url", "URL of dependency", True, "?")
        p_zigpkg_add.add_arg("name", "Name of dependency", True, "?")
        p_zigpkg_add.add_option("hash", "str", "?", "", "Hash of dependency")
        p_zigpkg_add.add_option("artifact", "strlist", "+", [], "Library artifact to link with")

        p_zigpkg_rm = p_zigpkg.add_cmd("remove", "Remove Zig package dependency", _cmd_zigpkg_rm)
        p_zigpkg_rm.add_arg("name", "Name of dependency", True, "?")

        return p.parse(env.argv)

    try:
        _args = _parse_args()
        _cmd = _args.cmd
        _file = None
        try:
            _file = _args.get_str("file")
        except argparse.ArgumentError:
            pass
        if _cmd is not None:
            if _file is not None and (_file.endswith(".act") or _file.endswith(".ty")):
                print("Error: cannot specify both a command and an .act/.ty file", err=True)
                await async env.exit(1)
            _cmd(_args)
        else:
            if _file is not None:
                _compilefile(_file, _args)
            else:
                env.exit(0)
    except argparse.PrintUsage as exc:
        print(exc.error_message)
        env.exit(0)
    except argparse.ArgumentError as exc:
        print(exc.error_message)
        env.exit(1)
