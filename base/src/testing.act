
import acton.rts
import argparse
import json
import logging
import term
import time

# -- assert ---------------------------------------------------------------------

# TODO: add actual values as args to assert functions
# TODO: add __str__ to assert exceptions
class NotEqualError[T](AssertionError):
    a: ?T
    b: ?T

    def __init__(self, a, b, msg: ?str=None):
        self.a = a
        self.b = b
        self.error_message = msg if msg is not None else "Expected equal values but they are non-equal."
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += " A: " + str(a) if a is not None else "None"
            b = self.b
            msg += " B: " + str(b) if b is not None else "None"
        return msg

class EqualError[T](AssertionError):
    a: ?T
    b: ?T

    def __init__(self, a, b, msg: ?str=None):
        self.a = a
        self.b = b
        self.error_message = msg if msg is not None else "Expected non-equal values but they are equal."
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += " A: " + str(a) if a is not None else "None"
            b = self.b
            msg += " B: " + str(b) if b is not None else "None"
        return msg

class NotTrueError[T](AssertionError):
    a: ?T

    def __init__(self, a, msg: ?str=None):
        self.a = a
        self.error_message = msg if msg is not None else "Expected True but got non-True"
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += ", value: " + str(a) if a is not None else "None"
        return msg

class NotFalseError[T](AssertionError):
    a: ?T

    def __init__(self, a, msg: ?str=None):
        self.a = a
        self.error_message = msg if msg is not None else "Expected False but got non-False."
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += ", value: " + str(a) if a is not None else "None"
        return msg

class NotNoneError[T](AssertionError):
    a: ?T

    def __init__(self, a, msg: ?str=None):
        self.a = a
        self.error_message = msg if msg is not None else "Expected None but got non-None."
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += ", value: " + str(a) if a is not None else "None"
        return msg

class NoneError[T](AssertionError):
    a: ?T

    def __init__(self, a, msg: ?str=None):
        self.a = a
        self.error_message = msg if msg is not None else "Expected non-None but got None."
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += ", value: " + str(a) if a is not None else "None"
        return msg

class NotInError[T,U](AssertionError):
    a: ?T
    b: ?U

    def __init__(self, a, b, msg: ?str=None):
        self.a = a
        self.b = b
        self.error_message = msg if msg is not None else "Expected element not in container"
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += ", element: " + str(a) if a is not None else "None"
            b = self.b
            msg += ", container: " + str(b) if b is not None else "None"
        return msg

class InError[T,U](AssertionError):
    a: ?T
    b: ?U

    def __init__(self, a, b, msg: ?str=None):
        self.a = a
        self.b = b
        self.error_message = msg if msg is not None else "Expected element in container"
        self.print_vals = True if msg is None else False

    def __str__(self):
        msg = "%s: %s" % (self._name(), self.error_message)
        if self.print_vals:
            a = self.a
            msg += ", element: " + str(a) if a is not None else "None"
            b = self.b
            msg += ", container: " + str(b) if b is not None else "None"
        return msg

class NotIsError[T(Identity)](AssertionError):
    a: ?T
    b: ?T
    def __init__(self, a, b, msg: ?str=None):
        self.a = a
        self.b = b
        self.error_message = msg if msg is not None else "a is not b"

class IsError[T(Identity)](AssertionError):
    a: ?T
    b: ?T
    def __init__(self, a, b, msg: ?str=None):
        self.a = a
        self.b = b
        self.error_message = msg if msg is not None else "a is b"

class NotRaisesError(AssertionError):
    def __init__(self, msg):
        self.error_message = msg
        self.a = None

class IsInstanceError(AssertionError):
    def __init__(self, msg):
        self.error_message = msg
        self.a = None
        self.b = None

class NotIsInstanceError(AssertionError):
    def __init__(self, msg):
        self.error_message = msg
        self.a = None
        self.b = None


def assertEqual[T(Eq)](a: ?T, b: ?T, msg: ?str):
    if a is not None and b is not None and not (a == b):
        raise NotEqualError(a, b, msg)

def assertNotEqual(a, b, msg: ?str):
    if not (a != b):
        raise EqualError(a, b, msg)

def assertTrue(a, msg: ?str):
    if not bool(a):
        raise NotTrueError(a, msg)

def assertFalse(a, msg: ?str):
    if bool(a):
        raise NotFalseError(a, msg)

# We cannot test raises right now because we need better support for taking a
# function and its arguments as parameters or run as a context manager
# TODO: assertRaises
# TODO: assertRaisesWithMessage
# TODO: assertRaisesWithMessageRegex

# TODO: fix this
#def assertIs[T(Identity)](a: ?T, b: ?T, msg: ?str):
#    if not (a is b):
#        raise NotIsError(a, b, msg)
# TODO: fix this
#def assertIsNot[T(Identity)](a: ?T, b: ?T, msg: ?str):
#    if not (a is not b):
#        raise IsError(a, b, msg)

def assertIsNone(a, msg: ?str):
    if not (a is None):
        raise NotNoneError(a, msg)

def assertIsNotNone(a, msg: ?str):
    if not (a is not None):
        raise NoneError(a, msg)

def assertIn(a, b, msg: ?str):
    if not (a in b):
        raise NotInError(a, b, msg)

def assertNotIn(a, b, msg: ?str):
    if a in b:
        raise InError(a, b, msg)

# TODO: fix this?
#def assertIsInstance(a, b, msg: str):
#    if not isinstance(a, b):
#        assert_msg = "Expected instance of " + b + " but got non-instance"
#        if msg != "":
#            assert_msg += ": " + msg
#        raise NotIsInstanceError(assert_msg)
#
#def assertNotIsInstance(a, b, msg: str):
#    if isinstance(a, b):
#        assert_msg = "Expected not instance of " + b + " but got instance"
#        if msg != "":
#            assert_msg += ": " + msg
#        raise IsInstanceError(assert_msg)


# -------------------------------------------------------------------------------

class TestLogger(logging.Logger):
    pass

class Test(object):
    name: str
    desc: str

    def __init__(self, name: str, desc: str):
        self.name = name
        self.desc = desc

    def to_json(self):
        return {
            "name": self.name,
            "desc": self.desc,
        }

    @staticmethod
    def from_json(data: dict[str, str]):
        name = data["name"]
        desc = data["desc"]
        if isinstance(name, str) and isinstance(desc, str):
            return Test(name, desc)
        else:
            raise ValueError("Invalid Test JSON")

class UnitTest(Test):
    def __init__(self, fn: mut() -> None, name: str, desc: str):
        self.fn = fn
        self.name = name
        self.desc = desc

class SyncActorTest(Test):
    def __init__(self, fn: proc(logging.Handler) -> None, name: str, desc: str):
        self.fn = fn
        self.name = name
        self.desc = desc

class AsyncActorTest(Test):
    def __init__(self, fn: proc(action(?bool, ?Exception) -> None, logging.Handler) -> None, name: str, desc: str):
        self.fn = fn
        self.name = name
        self.desc = desc

class EnvTest(Test):
    def __init__(self, fn: proc(action(?bool, ?Exception) -> None, Env, logging.Handler) -> None, name: str, desc: str):
        self.fn = fn
        self.name = name
        self.desc = desc


class TestResult(object):
    """
    There are three possible outcomes for a test:
    - success: the test ran to completion with the expected results
      - for unit tests & synchronous actor tests, it means it returned `None`
      - for asynchronous actor & env tests, the report_result callback was called with TestResult(success=True, exception=None)
    - failure: the test encountered an unexpected value
      - for unit tests & synchronous actor tests, an AssertionError (or child thereof) was raiesd
      - for asynchronous actor & env tests, the report_result callback was called with TestResult(success=False, exception=AssertionError)
    - error: the test was unable to run to completion, encountering some other error in test setup or similar
      - for unit tests & synchronous actor tests, an Exception (or child thereof) was raised, but not an AssertionError
      - for asynchronous actor & env tests, the report_result callback was called with TestResult(success=None, exception=AssertionError)
    """
    success: ?bool
    exception: ?str
    duration: float

    def __init__(self, success: ?bool, exception: ?str, duration: float):
        self.success = success
        self.exception = exception
        self.duration = duration

    def to_json(self):
        return {
            "success": self.success,
            "exception": self.exception,
            "duration": self.duration,
        }

    @staticmethod
    def from_json(data: dict[str, str]) -> TestResult:
        success = data["success"]
        exception = data["exception"]
        duration = data["duration"]
        if (isinstance(success, bool)
            and isinstance(exception, str)
            and isinstance(duration, float)
            ):
            return TestResult(success, exception, duration)
        raise ValueError("Invalid TestResult JSON")


class TestInfo(object):
    definition: Test
    complete: bool
    success: ?bool
    exception: ?str
    flaky: bool
    min_duration: float
    max_duration: float
    avg_duration: float
    total_duration: float
    num_iterations: int
    num_failures: int
    num_errors: int
    results: list[TestResult]

    def __init__(self, definition: Test, complete: bool=False, success: ?bool=None, exception: ?str=None, flaky: bool=False, min_duration: float=-1.0, max_duration: float=-1.0, avg_duration: float=-1.0, total_duration: float=-1.0, num_iterations: int=-1, num_failures: int=-1, num_errors: int=-1, results: list[TestResult]=[]):
        self.definition = definition
        self.complete = complete
        self.success = success
        self.exception = exception
        self.flaky = flaky
        self.min_duration = min_duration
        self.max_duration = max_duration
        self.avg_duration = avg_duration
        self.total_duration = total_duration
        self.num_iterations = num_iterations
        self.num_failures = num_failures
        self.num_errors = num_errors
        self.results = results

    def update(self, complete, result: TestResult):
        self.complete = complete
        self.results.append(result)
        exc = result.exception
        if exc is not None:
            self.exception = exc

        self.flaky = False
        self.min_duration = -1.0
        self.max_duration = -1.0
        self.avg_duration = -1.0
        self.total_duration = 0.0
        self.num_iterations = len(self.results)
        self.num_failures = 0
        self.num_errors = 0
        for result in self.results:
            res_success = result.success
            if res_success == False:
                self.num_failures += 1
            elif res_success is None:
                self.num_errors += 1

            if result.duration < self.min_duration or self.min_duration < 0.0:
                self.min_duration = result.duration
            if result.duration > self.max_duration or self.max_duration < 0.0:
                self.max_duration = result.duration
            self.total_duration += result.duration

        self.avg_duration = self.total_duration / float(self.num_iterations)
        if self.num_failures > 0:
            self.success = False
        elif self.num_errors > 0:
            self.success = None
        if (self.num_failures == 0 and self.num_errors == 0) or self.num_failures == self.num_iterations or self.num_errors == self.num_iterations:
            self.flaky = False
        else:
            self.flaky = True

    def to_json(self):
        return {
            "definition": self.definition.to_json(),
            "complete": self.complete,
            "success": self.success,
            "exception": self.exception,
            "flaky": self.flaky,
            "min_duration": self.min_duration,
            "max_duration": self.max_duration,
            "avg_duration": self.avg_duration,
            "total_duration": self.total_duration,
            "num_iterations": self.num_iterations,
            "num_failures": self.num_failures,
            "num_errors": self.num_errors,
            #"results": [r.to_json() for r in self.results],
        }

    @staticmethod
    def from_json(json_data):
        definition = Test.from_json(json_data["definition"])
        complete = json_data["complete"]
        success = json_data["success"]
        exc = json_data["exception"]
        flaky = json_data["flaky"]
        min_duration = json_data["min_duration"]
        max_duration = json_data["max_duration"]
        avg_duration = json_data["avg_duration"]
        total_duration = json_data["total_duration"]
        num_iterations = json_data["num_iterations"]
        num_failures = json_data["num_failures"]
        num_errors = json_data["num_errors"]
        results: list[TestResult] = []
        json_data_results = json_data["results"]
        if isinstance(json_data_results, list):
            for r in json_data_results:
                r_success = r["success"]
                r_exception = r["exception"]
                r_duration = r["duration"]
                if (isinstance(r_success, bool)
                    and isinstance(r_exception, str)
                    and isinstance(r_duration, float)
                    ):
                    results.append(TestResult(r_success, r_exception, r_duration))
                else:
                    raise ValueError("Invalid TestResult JSON")
        exception: ?str = None
        if isinstance(exc, str):
            exception = exc
        if (isinstance(complete, bool)
            and isinstance(success, bool)
            and isinstance(flaky, bool)
            and isinstance(min_duration, float)
            and isinstance(max_duration, float)
            and isinstance(avg_duration, float)
            and isinstance(total_duration, float)
            and isinstance(num_iterations, int)
            and isinstance(num_failures, int)
            and isinstance(num_errors, int)
            ):
            return TestInfo(definition, complete, success, exception, flaky, min_duration, max_duration, avg_duration, total_duration, num_iterations, num_failures, num_errors, results)
        else:
            raise ValueError("Invalid TestInfo JSON")

# TODO: make this configurable
# It doesn't seem to work well bumping up this value much beyond a few ms.
# Probably because we are sending a test_result update for each test run which
# becomes excessively chatty. Should probably summarize results and send the
# summary at a lower frequency.
MIN_TEST_DURATION = 1.0

actor unit_test_runner(i, get_test, report_result):
    """Test runner for unit tests
    """
    def _run_fn(f):
        sw = time.Stopwatch()
        try:
            f()
            dur = sw.elapsed().to_float() * 1000.0
            return TestResult(True, None, dur)
        except AssertionError as e:
            dur = sw.elapsed().to_float() * 1000.0
            return TestResult(False, str(e), dur)
        except Exception as e:
            dur = sw.elapsed().to_float() * 1000.0
            return TestResult(None, str(e), dur)

    def _run():
        while True:
            t = get_test()
            if t is not None:
                f = t.fn
                total_dur = 0.0
                complete = False
                while True:
                    test_result = _run_fn(f)
                    total_dur += test_result.duration
                    if total_dur > MIN_TEST_DURATION:
                        complete = True
                    report_result(t, complete, test_result)
                    if complete:
                        break
            else:
                return None

    after 0: _run()


# TODO: collapse this and the above unit_test_runner, since both are sync tests
# and the only difference is the type of test, so I think this should be
# possible
# TODO: investigate if we can turn this into async style, which would open up
# for collapsing this with the async_actor_test_runner and env_test_runner
actor sync_actor_test_runner(get_test: action() -> ?SyncActorTest, report_result):
    """Test runner for sync actor tests
    """
    log_handler = logging.Handler("TestRunner")

    def _run_fn(f):
        sw = time.Stopwatch()
        try:
            f(log_handler)
            dur = sw.elapsed().to_float() * 1000.0
            return TestResult(True, None, dur)
        except AssertionError as e:
            dur = sw.elapsed().to_float() * 1000.0
            return TestResult(False, str(e), dur)
        except Exception as e:
            dur = sw.elapsed().to_float() * 1000.0
            return TestResult(None, str(e), dur)

    def _run():
        while True:
            t = get_test()
            if t is not None:
                f = t.fn
                total_dur = 0.0
                complete = False
                while True:
                    test_result = _run_fn(f)
                    total_dur += test_result.duration
                    if total_dur > MIN_TEST_DURATION:
                        complete = True
                    report_result(t, complete, test_result)
                    if complete:
                        break
            else:
                return None

    after 0: _run()


# TODO: add a timeout to this
actor async_actor_test_runner(get_test: action() -> ?AsyncActorTest, report_result):
    """Test runner for async actor tests
    """
    log_handler = logging.Handler("TestRunner")
    var total_duration = 0.0

    action def _report_result(test: AsyncActorTest, sw, success: ?bool, exception: ?Exception):
        dur = sw.elapsed().to_float() * 1000.0
        total_duration += dur
        complete = False
        if total_duration > MIN_TEST_DURATION:
            complete = True
        exc = None
        if exception is not None:
            exc = str(exception)
        report_result(test, complete, TestResult(success, exc, dur))
        if not complete:
            _run_fn(test)
        else:
            _run_next()

    def _run_fn(t):
        sw = time.Stopwatch()
        f = t.fn
        try:
            f(lambda s, e: _report_result(t, sw, s, e), log_handler)
        except AssertionError as e:
            _report_result(t, sw, False, e)
        except Exception as e:
            _report_result(t, sw, None, e)

    def _run_next():
        """Get the next available test and run it"""
        total_duration = 0.0
        t = get_test()
        if t is not None:
            _run_fn(t)

    after 0: _run_next()


actor env_test_runner(get_test: action() -> ?EnvTest, report_result, env):
    """Test runner for async actor tests
    """
    log_handler = logging.Handler("TestRunner")
    var total_duration = 0.0

    action def _report_result(test: EnvTest, sw, success: ?bool, exception: ?Exception):
        dur = sw.elapsed().to_float() * 1000.0
        total_duration += dur
        complete = False
        if total_duration > MIN_TEST_DURATION:
            complete = True
        exc = None
        if exception is not None:
            exc = str(exception)
        report_result(test, complete, TestResult(success, exc, dur))
        if not complete:
            _run_fn(test)
        else:
            _run_next()

    def _run_fn(t):
        sw = time.Stopwatch()
        f = t.fn
        try:
            f(lambda s, e: _report_result(t, sw, s, e), env, log_handler)
        except AssertionError as e:
            _report_result(t, sw, False, e)
        except Exception as e:
            _report_result(t, sw, None, e)

    def _run_next():
        """Get the next available test and run it"""
        total_duration = 0.0
        t = get_test()
        if t is not None:
            _run_fn(t)

    after 0: _run_next()


class ProjectTestResults(object):
    _env: Env
    results: dict[str, dict[str, TestInfo]]
    sw: time.Stopwatch
    expected_modules: set[str]
    printed_lines: int
    last_print: time.Instant

    def __init__(self, env):
        self._env = env
        self.results = {}
        self.sw = time.Stopwatch()
        self.expected_modules = set([''])
        self.printed_lines = 0
        self.last_print = time.monotonic()
        self.last_print.second -= 1

    def set_expected(self, tests: dict[str, Test], modname: str=""):
        for test_name, test in tests.items():
            if modname not in self.results:
                self.results[modname] = {}
            self.results[modname][test_name] = TestInfo(test)

    def update_module(self, module_name: str, test_results: dict[str, TestInfo]):
        """Update test results for all tests in a module
        """
        self.results[module_name] = test_results

    def update(self, module_name: str, test: Test, complete: bool, test_result: TestResult):
        """Update result for individual test
        """
        if module_name not in self.results:
            self.results[module_name] = {}
        if test.name not in self.results[module_name]:
            self.results[module_name][test.name] = TestInfo(test)
        tres = self.results[module_name][test.name]
        if test_result is not None:
            tres.update(complete, test_result)

    def num_tests(self):
        cnt = 0
        for module_name in self.results:
            cnt += len(self.results[module_name])
        return cnt

    def skip_show(self):
        if len(self.expected_modules) > 0 and set(self.results.keys()) != self.expected_modules:
            return True
        return False

    def is_test_done(self, modname, name):
        if modname in self.results and name in self.results[modname]:
            test_info = self.results[modname][name]
            return test_info.complete
        return False

    def show_updated(self, test, complete, test_result, modname):
        pass

    def show(self):
        if self.skip_show():
            return

        complete = True
        if set(self.results.keys()) != self.expected_modules:
            complete = False
        for module_name in self.results:
            for test_name, test_info in self.results[module_name].items():
                if not test_info.complete:
                    complete = False

        now = time.monotonic()
        if now.since(self.last_print).to_float() < 0.05:
            return
        self.last_print = now

        errors = 0
        failures = 0

        for i in range(self.printed_lines):
            print(term.clearline + term.up() + term.clearline, end="")
        self.printed_lines = 0
        tname_width = 20
        for modname in self.results:
            for tname, tinfo in self.results[modname].items():
                tname_width = max([tname_width, len(tinfo.definition.name)])
        tname_width += 5

        for modname in self.results:
            if modname == "":
                print("\nTests")
                self.printed_lines += 2
            elif len(self.results[modname]) > 0:
                print("\nTests - module %s:" % modname)
                self.printed_lines += 2
            for tname, tinfo in self.results[modname].items():
                prefix = "  " + tinfo.definition.name + ": "
                prefix += " " * (tname_width - len(prefix))
                success = tinfo.success
                exc = tinfo.exception
                if tinfo.complete:
                    if exc is not None:
                        flaky_info = "("
                        msg = ""
                        if tinfo.flaky:
                            msg = "FLAKY "
                        if tinfo.num_errors > 0:
                            msg += "ERROR"
                            errors += 1
                            flaky_info += "%d errors" % tinfo.num_errors
                        if tinfo.num_errors > 0 and tinfo.num_failures > 0:
                            msg += "/"
                            flaky_info += " and "
                        if tinfo.num_failures > 0:
                            msg += "FAIL"
                            failures += 1
                            flaky_info += "%d failures" % tinfo.num_failures
                        flaky_info += " out of %d runs in %3.3fms)" % (tinfo.num_iterations, tinfo.total_duration)

                        print(prefix + term.bold + term.red + msg + " " + flaky_info + term.normal)
                        self.printed_lines += 1
                        for line in str(exc).splitlines(None):
                            print(term.red + "    %s" % (line) + term.normal)
                            self.printed_lines += 1
                    else:
                        print(prefix + term.green + "OK (%3d runs in %-3.3fms)" % (tinfo.num_iterations, tinfo.total_duration) + term.normal)
                        self.printed_lines += 1
                else:
                    print(prefix + term.bold + term.yellow + "RUNNING (%3d runs in %.3fms)" % (tinfo.num_iterations, tinfo.total_duration) + term.normal)
                    self.printed_lines += 1
        if complete:
            print("")
            if errors > 0 and failures > 0:
                print(term.bold + term.red + "%d error and %d failure out of %d tests (%ss)" % (errors, failures, self.num_tests(), self.sw.elapsed().str_ms()) + term.normal)
                print()
                self._env.exit(2)
            elif errors > 0:
                print(term.bold + term.red + "%d out of %d tests errored (%ss)" % (errors, self.num_tests(), self.sw.elapsed().str_ms()) + term.normal)
                print()
                self._env.exit(2)
            elif failures > 0:
                print(term.bold + term.red + "%d out of %d tests failed (%ss)" % (failures, self.num_tests(), self.sw.elapsed().str_ms()) + term.normal)
                print()
                self._env.exit(1)
            else:
                print(term.green + "All %d tests passed (%ss)" % (self.num_tests(), self.sw.elapsed().str_ms()) + term.normal)
                print()
                self._env.exit(0)

class ModuleTestResults(object):
    tests: dict[str, TestInfo]

    def __init__(self):
        self.tests = {}

    def set_tests(self, tests: dict[str, TestInfo]):
        self.tests = tests

    def update(self, test: Test, complete: bool, test_result: TestResult):
        if test.name not in self.tests:
            self.tests[test.name] = TestInfo(test)
        self.tests[test.name].update(complete, test_result)
        print(json.encode({"test": test.to_json(), "complete": complete, "result": test_result.to_json()}), stderr=True)

    def is_test_done(self, name):
        if name in self.tests:
            return self.tests[name].complete
        return False

    def show(self):
        res = {}
        for test in self.tests.values():
            res[test.definition.name] = test.definition.to_json()
        print(json.encode({"tests": res}), stderr=True)

    def show_updated(self, test, complete, test_result, modname):
        print(json.encode({"test": test.to_json(), "complete": complete, "result": test_result.to_json()}), stderr=True)



actor test_runner(env: Env, unit_tests: dict[str, UnitTest], sync_actor_tests: dict[str, SyncActorTest], async_actor_tests: dict[str, AsyncActorTest], env_tests: dict[str, EnvTest]):
    sw = time.Stopwatch()
    var results = ModuleTestResults()

    def _init_results(args):

        all_tests = {}
        for name, t in unit_tests.items():
            all_tests[name] = t
        for name, t in sync_actor_tests.items():
            all_tests[name] = t
        for name, t in async_actor_tests.items():
            all_tests[name] = t
        for name, t in env_tests.items():
            all_tests[name] = t

        tests = _filter_tests(all_tests, args)

        test_module_results = {}
        for test_def in tests.values():
            test_module_results[test_def.name] = TestInfo(test_def)
        results.set_tests(test_module_results)

    def _filter_tests[T](tests: dict[str, T], args) -> dict[str, T]:
        res = {}
        name_filter = []
        try:
            name_filter = args.get_strlist("name")
        except argparse.ArgumentError:
            pass
        test_names = set(name_filter)
        if test_names == set():
            return tests

        TEST_PREFIX_LEN = len("_test_")
        for name, t in tests.items():
            if name[TEST_PREFIX_LEN:] in test_names:
                res[name] = t
        return res

    proc def _list_tests(args):
        _init_results(args)
        tests = []
        for test in results.tests.values():
            tests.append(test.definition.to_json())
        print(json.encode({"tests": tests}), stderr=True)
        env.exit(0)

    proc def _run_tests(args):
        _init_results(args)
        results.show()
        # start with unit tests, proceed with next test category after unit tests
        _run_unit_tests(args)

    proc def _run_unit_tests(args):
        my_tests = _filter_tests(unit_tests, args)
        handed_out = set()

        def get_test() -> ?UnitTest:
            remaining = list(set(my_tests.keys()) - handed_out)
            if len(remaining) > 0:
                test_name = remaining[0]
                handed_out.add(test_name)
                test = my_tests[test_name]
                return test

        def check_complete():
            for test in my_tests.values():
                if not results.is_test_done(test.name):
                    return False
            _run_sync_actor_tests(args)
            return True

        def report_result(t, complete, test_result: TestResult):
            results.update(t, complete, test_result)
            check_complete()

        if not check_complete():
            for i in range(env.nr_wthreads):
                unit_test_runner(i, get_test, report_result)

    proc def _run_sync_actor_tests(args):
        my_tests = _filter_tests(sync_actor_tests, args)
        handed_out = set()

        def get_test() -> ?SyncActorTest:
            remaining = list(set(my_tests.keys()) - handed_out)
            if len(remaining) > 0:
                test_name = remaining[0]
                handed_out.add(test_name)
                test = my_tests[test_name]
                return test

        def check_complete():
            for test in my_tests.values():
                if not results.is_test_done(test.name):
                    return False
            _run_async_actor_tests(args)
            return True

        def report_result(t, complete, test_result: TestResult):
            results.update(t, complete, test_result)
            check_complete()

        if not check_complete():
            for i in range(0, min([1, env.nr_wthreads // 4], None), 1):
                sync_actor_test_runner(get_test, report_result)

    proc def _run_async_actor_tests(args):
        my_tests = _filter_tests(async_actor_tests, args)
        handed_out = set()

        def get_test() -> ?AsyncActorTest:
            remaining = list(set(my_tests.keys()) - handed_out)
            if len(remaining) > 0:
                test_name = remaining[0]
                handed_out.add(test_name)
                test = my_tests[test_name]
                return test

        def check_complete():
            for test in my_tests.values():
                if not results.is_test_done(test.name):
                    return False
            _run_env_tests(args)
            return True

        def report_result(t, complete, test_result: TestResult):
            results.update(t, complete, test_result)
            check_complete()

        if not check_complete():
            for i in range(0, min([1, env.nr_wthreads // 4], None), 1):
                async_actor_test_runner(get_test, report_result)

    proc def _run_env_tests(args):
        my_tests = _filter_tests(env_tests, args)
        handed_out = set()

        def get_test() -> ?EnvTest:
            remaining = list(set(my_tests.keys()) - handed_out)
            if len(remaining) > 0:
                test_name = remaining[0]
                handed_out.add(test_name)
                test = my_tests[test_name]
                return test

        def check_complete():
            for test in my_tests.values():
                if not results.is_test_done(test.name):
                    return False
            env.exit(0)
            return True

        def report_result(t, complete, test_result: TestResult):
            results.update(t, complete, test_result)
            check_complete()

        if not check_complete():
            for i in range(0, min([1, env.nr_wthreads // 4], None), 1):
                env_test_runner(get_test, report_result, env)



    proc def _run_perf_tests(args):
        print("Running performance tests")
        # - disable GC
        acton.rts.disable_gc(env.syscap)

        all_good = True
        for ut in unit_tests.values():
            test_res = []
            try:
                for iteration in range(args.get_int("iterations")):
                    acton.rts.gc(env.syscap) # explicit GC collection
                    mem_before = acton.rts.get_mem_usage(env.syscap)
                    sw = time.Stopwatch()
                    ut.fn() # run test function
                    dur = sw.elapsed().to_float() * 1000.0
                    mem_after = acton.rts.get_mem_usage(env.syscap)
                    gc_sw = time.Stopwatch()
                    acton.rts.gc(env.syscap)
                    gc_dur = gc_sw.elapsed().to_float() * 1000.0
                    mem_usage = mem_after - mem_before
                    test_res.append((dur=dur, gc_dur=gc_dur, mem_usage=mem_usage))

                total_mem_usage = 0
                min_dur = 999999999999.0
                max_dur = 0.0
                total_dur = 0.0
                total_gc_dur = 0.0
                for res in test_res:
                    total_mem_usage += int(res.mem_usage)
                    min_dur = min([min_dur, res.dur], None)
                    max_dur = max([max_dur, res.dur], None)
                    total_dur += res.dur
                    total_gc_dur += res.gc_dur

                avg_mem_usage = total_mem_usage / len(test_res)
                avg_dur = total_dur / float(len(test_res))
                avg_gc_dur = total_gc_dur / float(len(test_res))
                print("Test %s: %sOK%s" % (ut.name, str(term.green), str(term.normal)))
                print("   iterations  : %12d" % args.get_int("iterations"))
                print("   CPU time    : %12f / %12f / %12f ms min/avg/max" % (min_dur, avg_dur, max_dur))
                print("   Mem usage   : %12d bytes (approximate)" % int(avg_mem_usage))
                print("   GC CPU time : %12f ms" % (avg_gc_dur))
            except AssertionError as exc:
                print("Test %s: %sFAILED%s" % (ut.name, term.bold + term.red, term.normal))
                for line in str(exc).splitlines(None):
                    print(term.red + "    %s" % (line) + term.normal)
                all_good = False
            except Exception as exc:
                print("Test %s: %sERROR%s" % (ut.name, term.bold + term.red, term.normal))
                for line in str(exc).splitlines(None):
                    print(term.red + "    %s" % (line) + term.normal)
                all_good = False

        acton.rts.enable_gc(env.syscap)
        if all_good:
            env.exit(0)
        else:
            env.exit(1)

    def _parse_args():
        p = argparse.Parser()
        p.add_bool("json", "Output results as JSON")
        lp = p.add_cmd("list", "list tests", _list_tests)
        tp = p.add_cmd("test", "Run tests", _run_tests)
        tp.add_option("name", "strlist", nargs="+", default=[], help="Filter tests by name")
        pp = p.add_cmd("perf", "Performance benchmark tests", _run_perf_tests)
        pp.add_option("iterations", "int", "?", 1, "Number of iterations to run")

        args = p.parse(env.argv)
        _cmd = args.cmd
        if _cmd is not None:
            _cmd(args)
        else:
            env.exit(0)
    try:
        _parse_args()
    except argparse.PrintUsage as exc:
        print(exc.error_message)
        env.exit(0)
    except argparse.ArgumentError as exc:
        print(exc.error_message)
        env.exit(1)
